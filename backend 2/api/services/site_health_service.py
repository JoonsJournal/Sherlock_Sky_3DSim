# backend/api/services/site_health_service.py
"""
site_health_service.py
Site Health Check ì„œë¹„ìŠ¤ - Phase 1 Multi-Site Connection ê¸°ë°˜ í™•ì¥

ì´ ì„œë¹„ìŠ¤ëŠ” ëª¨ë“  Siteì˜ ì—°ê²° ìƒíƒœë¥¼ ê´€ë¦¬í•˜ê³  ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.
Graceful Degradationê³¼ Exponential Backoff ì¬ì—°ê²°ì„ ì§€ì›í•©ë‹ˆë‹¤.

@version 1.0.0
@changelog
- v1.0.0: ì´ˆê¸° ë²„ì „ (2026-02-02)
          - ë‹¨ì¼/ì „ì²´ Site Health Check
          - Graceful Degradation (ì¼ë¶€ ì‹¤íŒ¨í•´ë„ ë‚˜ë¨¸ì§€ ë°˜í™˜)
          - Exponential Backoff ì¬ì—°ê²° (1s â†’ 2s â†’ 4s â†’ ... ìµœëŒ€ 30s)
          - âš ï¸ í˜¸í™˜ì„±: ì‹ ê·œ ì„œë¹„ìŠ¤ë¡œ ê¸°ì¡´ ì½”ë“œ ì˜í–¥ ì—†ìŒ

@dependencies
- asyncio
- backend.api.database.connection_test

ğŸ“ ìœ„ì¹˜: backend/api/services/site_health_service.py
ì‘ì„±ì¼: 2026-02-02
ìˆ˜ì •ì¼: 2026-02-02
"""

from typing import Dict, List, Optional, Any
from datetime import datetime, timezone
import asyncio
import logging
import time
import os
import json

logger = logging.getLogger(__name__)


# ============================================
# Constants
# ============================================

MAPPING_CONFIG_DIR = "config/site_mappings"
LAYOUT_CONFIG_DIR = "config/layouts"
DATABASES_CONFIG_FILE = "config/databases.json"

# ì¬ì—°ê²° ì„¤ì •
DEFAULT_MAX_RETRIES = 10
BASE_DELAY_SECONDS = 1
MAX_DELAY_SECONDS = 30

# Health Check ì„¤ì •
HEALTH_CHECK_TIMEOUT = 5  # seconds

# Region ë§¤í•‘
REGION_MAP = {
    "CN": ("China", "ğŸ‡¨ğŸ‡³"),
    "KR": ("Korea", "ğŸ‡°ğŸ‡·"),
    "VN": ("Vietnam", "ğŸ‡»ğŸ‡³"),
    "US": ("USA", "ğŸ‡ºğŸ‡¸"),
    "JP": ("Japan", "ğŸ‡¯ğŸ‡µ"),
}


class SiteHealthService:
    """
    Site Health Check ì„œë¹„ìŠ¤
    
    ëª¨ë“  Siteì˜ ì—°ê²° ìƒíƒœë¥¼ ê´€ë¦¬í•˜ê³  ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        self._connection_manager = None
        self._cached_sites: Dict[str, Dict] = {}
        self._health_cache: Dict[str, Dict] = {}
        self._cache_ttl = 10  # seconds
        self._last_cache_update: Optional[datetime] = None
        
        logger.info("âœ… SiteHealthService ì´ˆê¸°í™”")
    
    @property
    def connection_manager(self):
        """ConnectionManager lazy loading"""
        if self._connection_manager is None:
            from ..database.connection_test import get_connection_manager
            self._connection_manager = get_connection_manager()
            logger.info("ğŸ”— ConnectionManager ë¡œë“œ ì™„ë£Œ")
        return self._connection_manager
    
    def _load_databases_config(self) -> Dict[str, Any]:
        """databases.json ë¡œë“œ"""
        try:
            if os.path.exists(DATABASES_CONFIG_FILE):
                with open(DATABASES_CONFIG_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
            logger.warning(f"âš ï¸ databases.json íŒŒì¼ ì—†ìŒ: {DATABASES_CONFIG_FILE}")
            return {}
        except Exception as e:
            logger.error(f"âŒ databases.json ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    def _parse_site_id(self, site_id: str) -> Dict[str, str]:
        """Site ID íŒŒì‹±"""
        parts = site_id.split("_")
        
        if len(parts) >= 2:
            region = parts[0]
            factory = parts[1]
            process = parts[2] if len(parts) > 2 else "Unknown"
            system = parts[3] if len(parts) > 3 else "Sherlock"
            database = parts[4] if len(parts) > 4 else "SherlockSky"
        else:
            region, factory, process, system, database = "Unknown", site_id, "Unknown", "Unknown", "SherlockSky"
        
        region_name, flag = REGION_MAP.get(region, ("Unknown", "ğŸŒ"))
        
        return {
            "region_code": region, "region_name": region_name, "flag_emoji": flag,
            "factory": factory, "process": process, "system": system, "database": database,
            "display_name": f"{flag} {region}_{factory} - {process}"
        }
    
    def _get_mapping_status(self, site_name: str, db_name: str = "SherlockSky") -> Dict[str, Any]:
        """ë§¤í•‘ íŒŒì¼ ìƒíƒœ í™•ì¸"""
        mapping_file = f"equipment_mapping_{site_name}_{db_name}.json"
        file_path = os.path.join(MAPPING_CONFIG_DIR, mapping_file)
        
        if not os.path.exists(file_path):
            return {"exists": False, "equipment_count": 0, "file_name": mapping_file, "last_updated": None}
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            mappings = data.get("mappings", {})
            mtime = os.path.getmtime(file_path)
            return {
                "exists": True, "equipment_count": len(mappings), "file_name": mapping_file,
                "last_updated": datetime.fromtimestamp(mtime, tz=timezone.utc).isoformat()
            }
        except Exception as e:
            logger.error(f"âŒ ë§¤í•‘ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {file_path} - {e}")
            return {"exists": False, "equipment_count": 0, "file_name": mapping_file, "last_updated": None, "error": str(e)}
    
    def _get_layout_status(self, site_name: str, db_name: str = "SherlockSky") -> Dict[str, Any]:
        """Layout íŒŒì¼ ìƒíƒœ í™•ì¸"""
        layout_file = f"{site_name}_{db_name}_layout.json"
        file_path = os.path.join(LAYOUT_CONFIG_DIR, layout_file)
        
        if not os.path.exists(file_path):
            # ëŒ€ì•ˆ íŒŒì¼ëª… ì‹œë„
            alt_layout_file = f"{site_name}_layout.json"
            alt_file_path = os.path.join(LAYOUT_CONFIG_DIR, alt_layout_file)
            
            if os.path.exists(alt_file_path):
                return {
                    "exists": True, "file_name": alt_layout_file,
                    "last_updated": datetime.fromtimestamp(os.path.getmtime(alt_file_path), tz=timezone.utc).isoformat()
                }
            return {"exists": False, "file_name": layout_file}
        
        return {
            "exists": True, "file_name": layout_file,
            "last_updated": datetime.fromtimestamp(os.path.getmtime(file_path), tz=timezone.utc).isoformat()
        }
    
    def get_all_configured_sites(self) -> List[str]:
        """ì„¤ì •ëœ ëª¨ë“  Site ID ëª©ë¡ ë°˜í™˜"""
        databases = self._load_databases_config()
        return list(databases.keys())
    
    async def _test_db_connection(self, site_name: str, db_name: str) -> Dict[str, Any]:
        """
        DB ì—°ê²° í…ŒìŠ¤íŠ¸ (ë¹„ë™ê¸°)
        
        Args:
            site_name: Site ì´ë¦„ (ì˜ˆ: CN_AAAA_Cutting_Sherlock)
            db_name: DB ì´ë¦„ (ì˜ˆ: SherlockSky)
        
        Returns:
            {success: bool, response_time_ms: int, error: str|None}
        """
        start_time = time.time()
        
        try:
            result = self.connection_manager.test_single_connection(site_name, db_name)
            end_time = time.time()
            response_time = int((end_time - start_time) * 1000)
            
            return {
                "success": result.get("success", False),
                "response_time_ms": response_time,
                "error": result.get("error") if not result.get("success") else None
            }
        except asyncio.TimeoutError:
            logger.warning(f"âš ï¸ ì—°ê²° íƒ€ì„ì•„ì›ƒ: {site_name}/{db_name}")
            return {"success": False, "response_time_ms": HEALTH_CHECK_TIMEOUT * 1000, "error": "Connection timeout"}
        except Exception as e:
            end_time = time.time()
            logger.error(f"âŒ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {site_name}/{db_name} - {e}")
            return {"success": False, "response_time_ms": int((end_time - start_time) * 1000), "error": str(e)}
    
    async def check_single_site_health(self, site_id: str) -> Optional[Dict[str, Any]]:
        """
        ë‹¨ì¼ Site Health Check
        
        Args:
            site_id: Site ID (ì˜ˆ: CN_AAAA_Cutting_Sherlock_SherlockSky)
        
        Returns:
            {site_id, display_name, status, db_connected, last_check, ...}
        """
        databases = self._load_databases_config()
        
        # Site ì°¾ê¸°
        matched_site = None
        matched_db = None
        
        for site_name in databases.keys():
            if site_id == site_name:
                matched_site = site_name
                matched_db = "SherlockSky"
                break
            elif site_id.startswith(site_name):
                matched_site = site_name
                remainder = site_id[len(site_name):].strip("_")
                matched_db = remainder if remainder else "SherlockSky"
                break
        
        if matched_site is None:
            logger.warning(f"âš ï¸ Site not found in config: {site_id}")
            return None
        
        # Site ì •ë³´ íŒŒì‹±
        parsed = self._parse_site_id(matched_site)
        
        # DB ì—°ê²° í…ŒìŠ¤íŠ¸
        db_result = await self._test_db_connection(matched_site, matched_db)
        
        # ë§¤í•‘/Layout ìƒíƒœ í™•ì¸
        mapping_status = self._get_mapping_status(matched_site, matched_db)
        layout_status = self._get_layout_status(matched_site, matched_db)
        
        # ìƒíƒœ ê²°ì •
        status = "healthy" if db_result["success"] else "unhealthy"
        
        logger.info(f"ğŸ“¡ Health Check: {site_id} â†’ {status} ({db_result['response_time_ms']}ms)")
        
        return {
            "site_id": site_id,
            "display_name": parsed["display_name"],
            "status": status,
            "db_connected": db_result["success"],
            "last_check": datetime.now(timezone.utc).isoformat(),
            "response_time_ms": db_result["response_time_ms"],
            "error_message": db_result["error"],
            "has_layout": layout_status["exists"],
            "has_mapping": mapping_status["exists"],
            "equipment_count": mapping_status.get("equipment_count", 0),
            "process": parsed["process"],
            "region": parsed["region_code"]
        }
    
    async def check_all_sites_health(self) -> Dict[str, Any]:
        """
        ì „ì²´ Site Health Check (Graceful Degradation)
        
        ëª¨ë“  Siteì— ëŒ€í•´ ë³‘ë ¬ë¡œ Health Checkë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        ì¼ë¶€ Siteê°€ ì‹¤íŒ¨í•´ë„ ë‚˜ë¨¸ì§€ ê²°ê³¼ëŠ” ì •ìƒ ë°˜í™˜ë©ë‹ˆë‹¤.
        """
        databases = self._load_databases_config()
        site_ids = list(databases.keys())
        
        results = {
            "total_sites": len(site_ids),
            "healthy_count": 0,
            "unhealthy_count": 0,
            "connecting_count": 0,
            "sites": [],
            "last_updated": datetime.now(timezone.utc).isoformat()
        }
        
        # ë³‘ë ¬ë¡œ Health Check ìˆ˜í–‰
        tasks = [self.check_single_site_health(site_id) for site_id in site_ids]
        site_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for site_id, result in zip(site_ids, site_results):
            if isinstance(result, Exception):
                # ì˜ˆì™¸ ë°œìƒí•œ ê²½ìš°
                parsed = self._parse_site_id(site_id)
                results["sites"].append({
                    "site_id": site_id, "display_name": parsed["display_name"],
                    "status": "unhealthy", "db_connected": False,
                    "last_check": datetime.now(timezone.utc).isoformat(),
                    "response_time_ms": None, "error_message": str(result),
                    "has_layout": False, "has_mapping": False, "equipment_count": 0,
                    "process": parsed["process"], "region": parsed["region_code"]
                })
                results["unhealthy_count"] += 1
                logger.error(f"âŒ Health Check ì˜ˆì™¸: {site_id} - {result}")
            elif result is None:
                logger.warning(f"âš ï¸ Site not found: {site_id}")
                continue
            else:
                results["sites"].append(result)
                if result.get("status") == "healthy":
                    results["healthy_count"] += 1
                elif result.get("status") == "connecting":
                    results["connecting_count"] += 1
                else:
                    results["unhealthy_count"] += 1
        
        logger.info(f"ğŸ“Š ì „ì²´ Health Check ì™„ë£Œ: Total={results['total_sites']}, Healthy={results['healthy_count']}, Unhealthy={results['unhealthy_count']}")
        return results
    
    async def reconnect_with_backoff(self, site_id: str, max_retries: int = DEFAULT_MAX_RETRIES) -> Dict[str, Any]:
        """
        Exponential Backoffìœ¼ë¡œ ì¬ì—°ê²°
        
        ì¬ì‹œë„ ê°„ê²©: 1ì´ˆ â†’ 2ì´ˆ â†’ 4ì´ˆ â†’ ... â†’ ìµœëŒ€ 30ì´ˆ
        
        Args:
            site_id: Site ID
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ 10íšŒ)
        """
        databases = self._load_databases_config()
        
        # Site ì°¾ê¸°
        matched_site = None
        matched_db = "SherlockSky"
        
        for site_name in databases.keys():
            if site_id == site_name or site_id.startswith(site_name):
                matched_site = site_name
                break
        
        if matched_site is None:
            logger.warning(f"âš ï¸ Site not found: {site_id}")
            return {"success": False, "message": f"Site not found: {site_id}", "attempts": 0, "final_status": "unknown"}
        
        logger.info(f"ğŸ”„ ì¬ì—°ê²° ì‹œì‘: {site_id} (ìµœëŒ€ {max_retries}íšŒ)")
        
        for attempt in range(1, max_retries + 1):
            try:
                result = await self._test_db_connection(matched_site, matched_db)
                
                if result["success"]:
                    logger.info(f"âœ… ì¬ì—°ê²° ì„±ê³µ: {site_id} (ì‹œë„ {attempt}/{max_retries})")
                    return {"success": True, "message": f"Reconnected after {attempt} attempt(s)", "attempts": attempt, "final_status": "healthy"}
                    
            except Exception as e:
                logger.warning(f"âš ï¸ ì¬ì—°ê²° ì‹œë„ {attempt} ì‹¤íŒ¨: {e}")
            
            # Exponential Backoff ëŒ€ê¸°
            if attempt < max_retries:
                delay = min(BASE_DELAY_SECONDS * (2 ** (attempt - 1)), MAX_DELAY_SECONDS)
                logger.info(f"â³ {delay}ì´ˆ í›„ ì¬ì‹œë„... ({attempt}/{max_retries})")
                await asyncio.sleep(delay)
        
        logger.error(f"âŒ ì¬ì—°ê²° ì‹¤íŒ¨: {site_id} ({max_retries}íšŒ ì‹œë„)")
        return {"success": False, "message": f"Failed to reconnect after {max_retries} attempts", "attempts": max_retries, "final_status": "unhealthy"}
    
    async def start_background_health_check(self, interval: int = 30):
        """ë°±ê·¸ë¼ìš´ë“œ Health Check ì‹œì‘"""
        logger.info(f"ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ Health Check ì‹œì‘ ({interval}ì´ˆ ê°„ê²©)")
        
        while True:
            try:
                results = await self.check_all_sites_health()
                self._health_cache = {site["site_id"]: site for site in results["sites"]}
                self._last_cache_update = datetime.now(timezone.utc)
            except Exception as e:
                logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ Health Check ì‹¤íŒ¨: {e}")
            
            await asyncio.sleep(interval)
    
    def get_cached_health(self, site_id: str) -> Optional[Dict[str, Any]]:
        """ìºì‹œëœ Health ì •ë³´ ë°˜í™˜"""
        return self._health_cache.get(site_id)


# ============================================
# Singleton Instance
# ============================================

_service_instance: Optional[SiteHealthService] = None


def get_site_health_service() -> SiteHealthService:
    """SiteHealthService ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _service_instance
    if _service_instance is None:
        _service_instance = SiteHealthService()
    return _service_instance