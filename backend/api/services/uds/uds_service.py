"""
uds_service.py
UDS ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì„œë¹„ìŠ¤
MSSQL ì§ì ‘ ì—°ê²° + JSON ë§¤í•‘ ë¡œë“œ + In-Memory ìƒíƒœ ìºì‹œ (Diffìš©)

@version 2.1.0
@description
- fetch_all_equipments: ë°°ì¹˜ ì¿¼ë¦¬ë¡œ ì „ì²´ ì„¤ë¹„ ì¡°íšŒ (117ê°œ)
- fetch_equipment_by_frontend_id: ë‹¨ì¼ ì„¤ë¹„ ì¡°íšŒ
- compute_diff: ì´ì „ ìƒíƒœì™€ í˜„ì¬ ìƒíƒœ ë¹„êµí•˜ì—¬ Delta ìƒì„±
- calculate_stats: ìƒíƒœë³„ í†µê³„ ê³„ì‚°

ğŸ†• v2.1.0: ì‹¤ì‹œê°„ ìƒì‚°ëŸ‰/Tact Time Delta ì—…ë°ì´íŠ¸
- compute_diff(): PRODUCTION_SNAPSHOT_QUERY, BATCH_TACT_TIME_QUERY ì¶”ê°€
- EquipmentSnapshotì— production_count, tact_time_seconds í¬í•¨
- Deltaì— ìƒì‚°ëŸ‰/Tact Time ë³€ê²½ì‚¬í•­ ì‹¤ì‹œê°„ ë°˜ì˜
- âš ï¸ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€

ğŸ†• v2.0.0: JSON ë§¤í•‘ í†µí•©
- _load_mapping_config(): Siteë³„ JSON ë§¤í•‘ íŒŒì¼ ë¡œë“œ
- _merge_with_mapping(): SQL ê²°ê³¼ + JSON ë§¤í•‘ ë³‘í•©
- _parse_frontend_id(): FrontendId â†’ (GridRow, GridCol) íŒŒì‹±
- equipment_id â†” frontend_id ì—­ë§¤í•‘ í…Œì´ë¸” ê´€ë¦¬

@changelog
- v2.1.0: ğŸ†• ì‹¤ì‹œê°„ ìƒì‚°ëŸ‰/Tact Time Delta ì—…ë°ì´íŠ¸ (2026-01-21)
          - compute_diff()ì—ì„œ PRODUCTION_SNAPSHOT_QUERY ì‹¤í–‰
          - compute_diff()ì—ì„œ BATCH_TACT_TIME_QUERY ì‹¤í–‰
          - EquipmentSnapshotì— production_count, tact_time_seconds í•„ë“œ ì‚¬ìš©
          - Deltaì— ìƒì‚°ëŸ‰/Tact Time ë³€ê²½ ì‹œ í¬í•¨
          - âš ï¸ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€
- v2.0.0: ğŸ”§ JSON ë§¤í•‘ í†µí•© (2026-01-21)
          - core.EquipmentMapping í…Œì´ë¸” ì œê±° (DBì— ì—†ìŒ)
          - JSON íŒŒì¼ì—ì„œ ë§¤í•‘ ì •ë³´ ë¡œë“œ
          - SQL ê²°ê³¼ì™€ ë§¤í•‘ ë³‘í•© ë¡œì§ ì¶”ê°€
          - equipment_id â†” frontend_id ì–‘ë°©í–¥ ë§¤í•‘
          - Site ë³€ê²½ ì‹œ ë§¤í•‘ ìºì‹œ ìë™ ê°±ì‹ 
          - âš ï¸ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€
- v1.0.0: ì´ˆê¸° ë²„ì „
          - MSSQL ì§ì ‘ ì—°ê²° (SQLAlchemy sync session)
          - In-Memory ìºì‹œë¡œ Diff ë¹„êµ
          - ë°°ì¹˜/ë‹¨ì¼ ì¿¼ë¦¬ ì§€ì›
          - âš ï¸ WITH (NOLOCK) ëª¨ë“  ì¿¼ë¦¬ì— ì ìš©ë¨

@dependencies
- sqlalchemy
- models/uds/uds_models.py
- services/uds/uds_queries.py
- database/multi_connection_manager.py

ğŸ“ ìœ„ì¹˜: backend/api/services/uds/uds_service.py
ì‘ì„±ì¼: 2026-01-20
ìˆ˜ì •ì¼: 2026-01-21
"""

from typing import List, Optional, Dict, Any, Tuple
import logging
import json
import os
from datetime import datetime
from contextlib import contextmanager

from sqlalchemy import text
from sqlalchemy.orm import Session

# UDS ëª¨ë¸ Import
from ...models.uds.uds_models import (
    EquipmentData,
    EquipmentStatus,
    StatusStats,
    DeltaUpdate,
    EquipmentSnapshot,
    compute_status_stats,
    compute_delta
)

# UDS ì¿¼ë¦¬ Import
# ğŸ†• v2.1.0: PRODUCTION_SNAPSHOT_QUERY ì¶”ê°€
from .uds_queries import (
    BATCH_EQUIPMENT_QUERY,
    SINGLE_EQUIPMENT_QUERY,
    PRODUCTION_COUNT_QUERY,
    PRODUCTION_SNAPSHOT_QUERY,  # ğŸ†• v2.1.0
    BATCH_TACT_TIME_QUERY,
    STATUS_SNAPSHOT_QUERY,
    calculate_memory_usage_percent,
    calculate_disk_usage_percent,
    parse_frontend_id,  # ğŸ†• v2.0.0
    generate_frontend_id  # ğŸ†• v2.0.0
)

# DB ì—°ê²° Import
from ...database.multi_connection_manager import connection_manager

logger = logging.getLogger(__name__)


# =============================================================================
# ğŸ†• v2.0.0: ë§¤í•‘ ê´€ë ¨ ìƒìˆ˜
# =============================================================================
MAPPING_CONFIG_DIR = "config/site_mappings"
DEFAULT_GRID_ROWS = 26
DEFAULT_GRID_COLS = 6


class UDSService:
    """
    Unified Data Store ì„œë¹„ìŠ¤
    
    [ì£¼ìš” ê¸°ëŠ¥]
    1. ì „ì²´ ì„¤ë¹„ ë°°ì¹˜ ì¡°íšŒ (ì´ˆê¸° ë¡œë“œ)
    2. ë‹¨ì¼ ì„¤ë¹„ ì¡°íšŒ (ìºì‹œ ë¯¸ìŠ¤ ì‹œ)
    3. Diff ê°ì§€ ë° Delta ìƒì„± (10ì´ˆ ì£¼ê¸°)
    4. ìƒíƒœë³„ í†µê³„ ê³„ì‚°
    
    ğŸ†• v2.1.0: ì‹¤ì‹œê°„ ìƒì‚°ëŸ‰/Tact Time Delta
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ compute_diff()ì—ì„œ 3ê°œ ì¿¼ë¦¬ ì‹¤í–‰:                             â”‚
    â”‚   1. STATUS_SNAPSHOT_QUERY - ìƒíƒœ/CPU/Memory                 â”‚
    â”‚   2. PRODUCTION_SNAPSHOT_QUERY - ìƒì‚°ëŸ‰ (ì˜¤ëŠ˜ ê¸°ì¤€)          â”‚
    â”‚   3. BATCH_TACT_TIME_QUERY - Tact Time (ìµœê·¼ ì‚¬ì´í´)         â”‚
    â”‚                                                              â”‚
    â”‚ Deltaì— í¬í•¨ë˜ëŠ” í•„ë“œ:                                        â”‚
    â”‚   - status, status_changed_at                                â”‚
    â”‚   - cpu_usage_percent, memory_usage_percent                  â”‚
    â”‚   - production_count (ğŸ†• v2.1.0)                             â”‚
    â”‚   - tact_time_seconds (ğŸ†• v2.1.0)                            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ğŸ†• v2.0.0: JSON ë§¤í•‘ í†µí•©
    5. Siteë³„ JSON ë§¤í•‘ íŒŒì¼ ë¡œë“œ
    6. SQL ê²°ê³¼ + ë§¤í•‘ ë³‘í•©
    7. equipment_id â†” frontend_id ì–‘ë°©í–¥ ì¡°íšŒ
    
    [In-Memory ìºì‹œ]
    - _previous_state: Dict[frontend_id, EquipmentSnapshot]
    - Diff ë¹„êµìš©ìœ¼ë¡œë§Œ ì‚¬ìš© (Frontendê°€ ë©”ì¸ ìºì‹œ)
    
    ğŸ†• v2.0.0: ë§¤í•‘ ìºì‹œ
    - _mapping_cache: Dict[equipment_id, MappingItem]
    - _reverse_mapping: Dict[frontend_id, equipment_id]
    - _current_site_id: í˜„ì¬ ë¡œë“œëœ Site ID
    
    [DB ì—°ê²°]
    - MultiConnectionManager ì‚¬ìš© (Site DB ë™ì  ì—°ê²°)
    - ëª¨ë“  ì¿¼ë¦¬ WITH (NOLOCK) ì ìš©
    """
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        # Diff ë¹„êµìš© In-Memory ìƒíƒœ ìºì‹œ
        self._previous_state: Dict[str, EquipmentSnapshot] = {}
        
        # ë§ˆì§€ë§‰ ì¡°íšŒ ì‹œê°„ (ë””ë²„ê¹…ìš©)
        self._last_fetch_time: Optional[datetime] = None
        
        # ===================================================================
        # ğŸ†• v2.0.0: ë§¤í•‘ ìºì‹œ
        # ===================================================================
        # equipment_id â†’ {frontend_id, equipment_name, grid_row, grid_col, ...}
        self._mapping_cache: Dict[int, Dict[str, Any]] = {}
        
        # frontend_id â†’ equipment_id (ì—­ë§¤í•‘)
        self._reverse_mapping: Dict[str, int] = {}
        
        # í˜„ì¬ ë¡œë“œëœ Site ID
        self._current_site_id: Optional[str] = None
        
        # ë§¤í•‘ ë¡œë“œ ì‹œê°„
        self._mapping_loaded_at: Optional[datetime] = None
        
        logger.info("ğŸš€ UDSService initialized (v2.1.0 - Realtime Production/TactTime Delta)")
    
    # ========================================================================
    # Context Manager: DB Session
    # ========================================================================
    
    @contextmanager
    def _get_session(self, site_id: str = None, db_name: str = None):
        """
        DB Session Context Manager
        
        Args:
            site_id: Site ID (Noneì´ë©´ ê¸°ë³¸ê°’)
            db_name: DB ì´ë¦„ (Noneì´ë©´ ê¸°ë³¸ê°’)
            
        Yields:
            Session: SQLAlchemy ì„¸ì…˜
        """
        session = connection_manager.get_session(site_id, db_name)
        try:
            yield session
        finally:
            session.close()
    
    # ========================================================================
    # ğŸ†• v2.0.0: JSON ë§¤í•‘ ë¡œë“œ
    # ========================================================================
    
    def _get_mapping_file_path(self, site_id: str) -> str:
        """
        Siteë³„ ë§¤í•‘ íŒŒì¼ ê²½ë¡œ
        
        Args:
            site_id: "korea_site1_line1" í˜•ì‹
            
        Returns:
            "config/site_mappings/equipment_mapping_korea_site1_line1.json"
        """
        return os.path.join(MAPPING_CONFIG_DIR, f"equipment_mapping_{site_id}.json")
    
    def _load_mapping_config(self, site_id: str, force_reload: bool = False) -> bool:
        """
        Siteë³„ JSON ë§¤í•‘ íŒŒì¼ ë¡œë“œ
        
        ğŸ†• v2.0.0: core.EquipmentMapping í…Œì´ë¸” ëŒ€ì‹  JSON íŒŒì¼ ì‚¬ìš©
        
        Args:
            site_id: Site ID (ì˜ˆ: "korea_site1_line1")
            force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
            
        Returns:
            bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
            
        Note:
            - ìºì‹œëœ Site IDì™€ ë™ì¼í•˜ë©´ ì¬ë¡œë“œ ì•ˆ í•¨ (force_reload=False)
            - íŒŒì¼ ì—†ìœ¼ë©´ ë¹ˆ ë§¤í•‘ìœ¼ë¡œ ì´ˆê¸°í™”
        """
        # ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ìŠ¤í‚µ
        if not force_reload and self._current_site_id == site_id:
            return True
        
        file_path = self._get_mapping_file_path(site_id)
        
        logger.info(f"ğŸ“‚ Loading mapping config: {file_path}")
        
        # ìºì‹œ ì´ˆê¸°í™”
        self._mapping_cache.clear()
        self._reverse_mapping.clear()
        
        if not os.path.exists(file_path):
            logger.warning(f"âš ï¸ Mapping file not found: {file_path}")
            self._current_site_id = site_id
            self._mapping_loaded_at = datetime.utcnow()
            return False
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            mappings = data.get("mappings", {})
            
            for frontend_id, item in mappings.items():
                equipment_id = item.get("equipment_id")
                if equipment_id is None:
                    continue
                
                # equipment_id â†’ mapping info
                self._mapping_cache[equipment_id] = {
                    "frontend_id": frontend_id,
                    "equipment_name": item.get("equipment_name", ""),
                    "equipment_code": item.get("equipment_code"),
                    "line_name": item.get("line_name"),
                    "grid_row": None,  # íŒŒì‹±ìœ¼ë¡œ ê³„ì‚°
                    "grid_col": None
                }
                
                # GridRow, GridCol íŒŒì‹±
                grid_row, grid_col = parse_frontend_id(frontend_id)
                self._mapping_cache[equipment_id]["grid_row"] = grid_row
                self._mapping_cache[equipment_id]["grid_col"] = grid_col
                
                # ì—­ë§¤í•‘: frontend_id â†’ equipment_id
                self._reverse_mapping[frontend_id] = equipment_id
            
            self._current_site_id = site_id
            self._mapping_loaded_at = datetime.utcnow()
            
            logger.info(f"âœ… Loaded {len(self._mapping_cache)} mappings for {site_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to load mapping config: {e}", exc_info=True)
            self._current_site_id = site_id
            self._mapping_loaded_at = datetime.utcnow()
            return False
    
    def _get_frontend_id(self, equipment_id: int) -> Optional[str]:
        """
        equipment_id â†’ frontend_id ë³€í™˜
        
        Args:
            equipment_id: DB Equipment ID
            
        Returns:
            frontend_id ë˜ëŠ” None (ë§¤í•‘ ì—†ìŒ)
        """
        mapping = self._mapping_cache.get(equipment_id)
        if mapping:
            return mapping.get("frontend_id")
        return None
    
    def _get_equipment_id(self, frontend_id: str) -> Optional[int]:
        """
        frontend_id â†’ equipment_id ë³€í™˜
        
        Args:
            frontend_id: Frontend ID (ì˜ˆ: "EQ-17-03")
            
        Returns:
            equipment_id ë˜ëŠ” None (ë§¤í•‘ ì—†ìŒ)
        """
        return self._reverse_mapping.get(frontend_id)
    
    def _get_mapping_info(self, equipment_id: int) -> Optional[Dict[str, Any]]:
        """
        equipment_idë¡œ ì „ì²´ ë§¤í•‘ ì •ë³´ ì¡°íšŒ
        
        Args:
            equipment_id: DB Equipment ID
            
        Returns:
            ë§¤í•‘ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
            {
                "frontend_id": "EQ-17-03",
                "equipment_name": "CVDF-001",
                "grid_row": 17,
                "grid_col": 3,
                ...
            }
        """
        return self._mapping_cache.get(equipment_id)
    
    def _derive_site_id_from_connection(self, db_site: str = None, db_name: str = None) -> str:
        """
        ì—°ê²° ì •ë³´ì—ì„œ Site ID ìœ ë„
        
        Args:
            db_site: Site í‚¤ (ì˜ˆ: "korea_site1")
            db_name: DB ì´ë¦„ (ì˜ˆ: "line1")
            
        Returns:
            Site ID (ì˜ˆ: "korea_site1_line1")
        """
        # ê¸°ë³¸ê°’ ì‚¬ìš©
        if not db_site:
            db_site = "korea_site1"  # TODO: connection_managerì—ì„œ ê°€ì ¸ì˜¤ê¸°
        if not db_name:
            db_name = "line1"  # TODO: connection_managerì—ì„œ ê°€ì ¸ì˜¤ê¸°
        
        return f"{db_site}_{db_name}"
    
    # ========================================================================
    # ë°°ì¹˜ ì¡°íšŒ: ì „ì²´ ì„¤ë¹„ ì´ˆê¸° ë¡œë“œ
    # ========================================================================
    
    def fetch_all_equipments(
        self,
        site_id: int = 1,
        line_id: int = 1,
        db_site: str = None,
        db_name: str = None
    ) -> List[EquipmentData]:
        """
        ì „ì²´ ì„¤ë¹„ ë°°ì¹˜ ì¡°íšŒ (ì´ˆê¸° ë¡œë“œ)
        
        GET /api/uds/initial ì—”ë“œí¬ì¸íŠ¸ì—ì„œ í˜¸ì¶œ.
        117ê°œ ì„¤ë¹„ ë°ì´í„°ë¥¼ í•œ ë²ˆì˜ ë°°ì¹˜ ì¿¼ë¦¬ë¡œ ì¡°íšŒ.
        
        ğŸ”§ v2.0.0 ë³€ê²½ì‚¬í•­:
          - SQL ì¿¼ë¦¬ì—ì„œ core.EquipmentMapping JOIN ì œê±°
          - JSON ë§¤í•‘ íŒŒì¼ ë¡œë“œ í›„ SQL ê²°ê³¼ì™€ ë³‘í•©
          - âš ï¸ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€ (í•˜ìœ„ í˜¸í™˜)
        
        Args:
            site_id: Factory Site ID (WHERE ì¡°ê±´)
            line_id: Factory Line ID (WHERE ì¡°ê±´)
            db_site: MultiConnectionManager Site í‚¤ (ê¸°ë³¸ê°’ ì‚¬ìš©)
            db_name: DB ì´ë¦„ (ê¸°ë³¸ê°’ ì‚¬ìš©)
            
        Returns:
            List[EquipmentData]: ì „ì²´ ì„¤ë¹„ ë°ì´í„° ëª©ë¡
            
        Raises:
            Exception: DB ì—°ê²° ë˜ëŠ” ì¿¼ë¦¬ ì‹¤íŒ¨ ì‹œ
        """
        logger.info(f"ğŸ“¡ Fetching all equipments (site_id={site_id}, line_id={line_id})")
        start_time = datetime.utcnow()
        
        # ===================================================================
        # ğŸ†• v2.0.0: ë§¤í•‘ íŒŒì¼ ë¡œë“œ (Site ë³€ê²½ ì‹œ ìë™ ê°±ì‹ )
        # ===================================================================
        mapping_site_id = self._derive_site_id_from_connection(db_site, db_name)
        self._load_mapping_config(mapping_site_id)
        
        with self._get_session(db_site, db_name) as session:
            try:
                # =============================================================
                # Step 1: ê¸°ë³¸ ì„¤ë¹„ ì •ë³´ ë°°ì¹˜ ì¡°íšŒ
                # ğŸ”§ v2.0.0: core.EquipmentMapping JOIN ì œê±°ë¨
                # =============================================================
                result = session.execute(
                    text(BATCH_EQUIPMENT_QUERY),
                    {"site_id": site_id, "line_id": line_id}
                )
                rows = result.fetchall()
                columns = result.keys()
                
                logger.info(f"  â†’ ê¸°ë³¸ ì¿¼ë¦¬: {len(rows)}ê±´ ì¡°íšŒ")
                
                # =============================================================
                # Step 2: ìƒì‚°ëŸ‰ ë°°ì¹˜ ì¡°íšŒ
                # ğŸ”§ v2.0.0: EquipmentIdë§Œ ë°˜í™˜ (FrontendId ì œê±°)
                # ğŸ› v2.1.0: COUNT(ct.Time) ì‚¬ìš© (CycleTimeId ì—†ìŒ)
                # =============================================================
                prod_result = session.execute(
                    text(PRODUCTION_COUNT_QUERY),
                    {"site_id": site_id, "line_id": line_id}
                )
                prod_rows = prod_result.fetchall()
                
                # ğŸ”§ v2.0.0: equipment_id ê¸°ë°˜ ë§µ (ê¸°ì¡´: frontend_id)
                # Column Index: [0] EquipmentId, [1] ProductionCount
                prod_map = {row[0]: row[1] for row in prod_rows}
                
                logger.info(f"  â†’ ìƒì‚°ëŸ‰ ì¿¼ë¦¬: {len(prod_map)}ê±´ ì¡°íšŒ")
                
                # =============================================================
                # Step 3: Tact Time ë°°ì¹˜ ì¡°íšŒ
                # ğŸ”§ v2.0.0: EquipmentIdë§Œ ë°˜í™˜ (FrontendId ì œê±°)
                # ğŸ› v2.1.0: ct.Time ì‚¬ìš© (StartTime ì—†ìŒ)
                # =============================================================
                tact_result = session.execute(
                    text(BATCH_TACT_TIME_QUERY),
                    {"site_id": site_id, "line_id": line_id}
                )
                tact_rows = tact_result.fetchall()
                
                # ğŸ”§ v2.0.0: equipment_id ê¸°ë°˜ ë§µ (ê¸°ì¡´: frontend_id)
                # Column Index: [0] EquipmentId, [1] TactTimeSeconds
                tact_map = {row[0]: row[1] for row in tact_rows}
                
                logger.info(f"  â†’ Tact Time ì¿¼ë¦¬: {len(tact_map)}ê±´ ì¡°íšŒ")
                
                # =============================================================
                # Step 4: EquipmentData ë³€í™˜ + ë§¤í•‘ ë³‘í•©
                # ğŸ†• v2.0.0: SQL ê²°ê³¼ + JSON ë§¤í•‘ ë³‘í•©
                # =============================================================
                equipments = []
                for row in rows:
                    row_dict = dict(zip(columns, row))
                    equipment = self._row_to_equipment_data(
                        row_dict, 
                        prod_map, 
                        tact_map
                    )
                    equipments.append(equipment)
                    
                    # In-Memory ìºì‹œ ì—…ë°ì´íŠ¸ (Diffìš©)
                    self._update_previous_state(equipment)
                
                # ì¡°íšŒ ì‹œê°„ ê¸°ë¡
                self._last_fetch_time = datetime.utcnow()
                elapsed_ms = (self._last_fetch_time - start_time).total_seconds() * 1000
                
                logger.info(f"âœ… Loaded {len(equipments)} equipments in {elapsed_ms:.1f}ms")
                return equipments
                
            except Exception as e:
                logger.error(f"âŒ Failed to fetch equipments: {e}", exc_info=True)
                raise
    
    # ========================================================================
    # ë‹¨ì¼ ì¡°íšŒ: Frontend IDë¡œ ì„¤ë¹„ ì¡°íšŒ
    # ========================================================================
    
    def fetch_equipment_by_frontend_id(
        self,
        frontend_id: str,
        db_site: str = None,
        db_name: str = None
    ) -> Optional[EquipmentData]:
        """
        ë‹¨ì¼ ì„¤ë¹„ ì¡°íšŒ
        
        GET /api/uds/equipment/{frontend_id} ì—”ë“œí¬ì¸íŠ¸ì—ì„œ í˜¸ì¶œ.
        âš ï¸ FrontendëŠ” UDS ìºì‹œë¥¼ ë¨¼ì € í™•ì¸í•˜ê³ , ìºì‹œ ë¯¸ìŠ¤ ì‹œì—ë§Œ í˜¸ì¶œí•´ì•¼ í•¨.
        
        ğŸ”§ v2.0.0 ë³€ê²½ì‚¬í•­:
          - frontend_id â†’ equipment_id ë³€í™˜ (JSON ë§¤í•‘ ì‚¬ìš©)
          - equipment_id ê¸°ë°˜ SQL ì¿¼ë¦¬ ì‹¤í–‰
          - ê²°ê³¼ì— ë§¤í•‘ ì •ë³´ ë³‘í•©
        
        Args:
            frontend_id: Frontend ID (ì˜ˆ: EQ-17-03)
            db_site: MultiConnectionManager Site í‚¤
            db_name: DB ì´ë¦„
            
        Returns:
            EquipmentData or None: ì„¤ë¹„ ë°ì´í„° (ì—†ìœ¼ë©´ None)
        """
        logger.info(f"ğŸ“¡ Fetching equipment: {frontend_id}")
        
        # ===================================================================
        # ğŸ†• v2.0.0: frontend_id â†’ equipment_id ë³€í™˜
        # ===================================================================
        mapping_site_id = self._derive_site_id_from_connection(db_site, db_name)
        self._load_mapping_config(mapping_site_id)
        
        equipment_id = self._get_equipment_id(frontend_id)
        
        if equipment_id is None:
            logger.warning(f"âš ï¸ No mapping found for frontend_id: {frontend_id}")
            return None
        
        with self._get_session(db_site, db_name) as session:
            try:
                # ğŸ”§ v2.0.0: equipment_id ê¸°ë°˜ ì¡°íšŒ
                result = session.execute(
                    text(SINGLE_EQUIPMENT_QUERY),
                    {"equipment_id": equipment_id}
                )
                row = result.fetchone()
                
                if not row:
                    logger.warning(f"âš ï¸ Equipment not found: {frontend_id} (equipment_id={equipment_id})")
                    return None
                
                columns = result.keys()
                row_dict = dict(zip(columns, row))
                
                # ìƒì‚°ëŸ‰, Tact Timeì€ ë‹¨ì¼ ì¡°íšŒ ì‹œ ë¯¸í¬í•¨ (ìºì‹œ ì‚¬ìš© ê¶Œì¥)
                equipment = self._row_to_equipment_data(row_dict, {}, {})
                
                logger.info(f"âœ… Equipment fetched: {frontend_id} -> {equipment.status}")
                return equipment
                
            except Exception as e:
                logger.error(f"âŒ Failed to fetch equipment {frontend_id}: {e}")
                raise
    
    # ========================================================================
    # ğŸ†• v2.0.0: Equipment IDë¡œ ì„¤ë¹„ ì¡°íšŒ (ì‹ ê·œ)
    # ========================================================================
    
    def fetch_equipment_by_id(
        self,
        equipment_id: int,
        db_site: str = None,
        db_name: str = None
    ) -> Optional[EquipmentData]:
        """
        Equipment IDë¡œ ë‹¨ì¼ ì„¤ë¹„ ì¡°íšŒ
        
        ğŸ†• v2.0.0 ì‹ ê·œ: equipment_id ê¸°ë°˜ ì§ì ‘ ì¡°íšŒ
        
        Args:
            equipment_id: DB Equipment ID
            db_site: MultiConnectionManager Site í‚¤
            db_name: DB ì´ë¦„
            
        Returns:
            EquipmentData or None
        """
        logger.info(f"ğŸ“¡ Fetching equipment by ID: {equipment_id}")
        
        mapping_site_id = self._derive_site_id_from_connection(db_site, db_name)
        self._load_mapping_config(mapping_site_id)
        
        with self._get_session(db_site, db_name) as session:
            try:
                result = session.execute(
                    text(SINGLE_EQUIPMENT_QUERY),
                    {"equipment_id": equipment_id}
                )
                row = result.fetchone()
                
                if not row:
                    logger.warning(f"âš ï¸ Equipment not found: equipment_id={equipment_id}")
                    return None
                
                columns = result.keys()
                row_dict = dict(zip(columns, row))
                
                equipment = self._row_to_equipment_data(row_dict, {}, {})
                
                logger.info(f"âœ… Equipment fetched: {equipment.frontend_id} -> {equipment.status}")
                return equipment
                
            except Exception as e:
                logger.error(f"âŒ Failed to fetch equipment {equipment_id}: {e}")
                raise
    
    # ========================================================================
    # ğŸ†• v2.1.0: Diff ê³„ì‚° - ìƒì‚°ëŸ‰/Tact Time ì‹¤ì‹œê°„ ë¹„êµ ì¶”ê°€
    # ========================================================================
    
    def compute_diff(
        self,
        site_id: int = 1,
        line_id: int = 1,
        db_site: str = None,
        db_name: str = None
    ) -> List[DeltaUpdate]:
        """
        ì´ì „ ìƒíƒœì™€ í˜„ì¬ ìƒíƒœ ë¹„êµí•˜ì—¬ Delta ìƒì„±
        
        Status Watcherê°€ 10ì´ˆë§ˆë‹¤ í˜¸ì¶œ.
        ë³€ê²½ëœ ì„¤ë¹„ë§Œ Deltaë¡œ ì¶”ì¶œí•˜ì—¬ WebSocket ì „ì†¡.
        
        ğŸ†• v2.1.0 ë³€ê²½ì‚¬í•­:
          - PRODUCTION_SNAPSHOT_QUERY ì‹¤í–‰í•˜ì—¬ ìƒì‚°ëŸ‰ ì¡°íšŒ
          - BATCH_TACT_TIME_QUERY ì‹¤í–‰í•˜ì—¬ Tact Time ì¡°íšŒ
          - EquipmentSnapshotì— production_count, tact_time_seconds í¬í•¨
          - Deltaì— ìƒì‚°ëŸ‰/Tact Time ë³€ê²½ì‚¬í•­ í¬í•¨
        
        ğŸ”§ v2.0.0 ë³€ê²½ì‚¬í•­:
          - STATUS_SNAPSHOT_QUERYê°€ EquipmentId ë°˜í™˜
          - equipment_id â†’ frontend_id ë³€í™˜ (JSON ë§¤í•‘)
          - Deltaì— frontend_id í¬í•¨
        
        [v2.1.0 ì¿¼ë¦¬ ì‹¤í–‰ ìˆœì„œ]
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 1. STATUS_SNAPSHOT_QUERY                                     â”‚
        â”‚    â†’ EquipmentId, Status, StatusChangedAt,                   â”‚
        â”‚      CpuUsagePercent, MemoryUsedMb, MemoryTotalMb            â”‚
        â”‚                                                              â”‚
        â”‚ 2. PRODUCTION_SNAPSHOT_QUERY (ğŸ†• v2.1.0)                     â”‚
        â”‚    â†’ EquipmentId, ProductionCount (ì˜¤ëŠ˜ 00:00 ì´í›„)          â”‚
        â”‚                                                              â”‚
        â”‚ 3. BATCH_TACT_TIME_QUERY (ğŸ†• v2.1.0)                         â”‚
        â”‚    â†’ EquipmentId, TactTimeSeconds (ìµœê·¼ ì‚¬ì´í´)              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        Args:
            site_id: Factory Site ID
            line_id: Factory Line ID
            db_site: DB Site í‚¤
            db_name: DB ì´ë¦„
            
        Returns:
            List[DeltaUpdate]: ë³€ê²½ëœ ì„¤ë¹„ Delta ëª©ë¡ (ë³€ê²½ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
        """
        if not self._previous_state:
            logger.warning("âš ï¸ No previous state for diff (run fetch_all first)")
            return []
        
        # ===================================================================
        # ğŸ†• v2.0.0: ë§¤í•‘ ë¡œë“œ í™•ì¸
        # ===================================================================
        mapping_site_id = self._derive_site_id_from_connection(db_site, db_name)
        self._load_mapping_config(mapping_site_id)
        
        with self._get_session(db_site, db_name) as session:
            try:
                # =============================================================
                # Step 1: ìƒíƒœ ìŠ¤ëƒ…ìƒ· ì¡°íšŒ (ê²½ëŸ‰ ì¿¼ë¦¬)
                # =============================================================
                status_result = session.execute(
                    text(STATUS_SNAPSHOT_QUERY),
                    {"site_id": site_id, "line_id": line_id}
                )
                status_rows = status_result.fetchall()
                
                # equipment_id â†’ status ì •ë³´ ë§µ
                # Column Index: [0] EquipmentId, [1] Status, [2] StatusChangedAt,
                #               [3] CpuUsagePercent, [4] MemoryUsedMb, [5] MemoryTotalMb
                status_map = {}
                for row in status_rows:
                    equipment_id = row[0]
                    if equipment_id:
                        status_map[equipment_id] = {
                            'status': row[1],
                            'status_changed_at': row[2],
                            'cpu_usage_percent': row[3],
                            'memory_used_mb': row[4],
                            'memory_total_mb': row[5]
                        }
                
                # =============================================================
                # ğŸ†• v2.1.0 Step 2: ìƒì‚°ëŸ‰ ìŠ¤ëƒ…ìƒ· ì¡°íšŒ
                # =============================================================
                prod_result = session.execute(
                    text(PRODUCTION_SNAPSHOT_QUERY),
                    {"site_id": site_id, "line_id": line_id}
                )
                prod_rows = prod_result.fetchall()
                
                # equipment_id â†’ production_count ë§µ
                # Column Index: [0] EquipmentId, [1] ProductionCount
                prod_map = {row[0]: row[1] for row in prod_rows}
                
                logger.debug(f"  â†’ ìƒì‚°ëŸ‰ Snapshot: {len(prod_map)}ê±´ ì¡°íšŒ")
                
                # =============================================================
                # ğŸ†• v2.1.0 Step 3: Tact Time ì¡°íšŒ
                # =============================================================
                tact_result = session.execute(
                    text(BATCH_TACT_TIME_QUERY),
                    {"site_id": site_id, "line_id": line_id}
                )
                tact_rows = tact_result.fetchall()
                
                # equipment_id â†’ tact_time_seconds ë§µ
                # Column Index: [0] EquipmentId, [1] TactTimeSeconds
                tact_map = {row[0]: row[1] for row in tact_rows}
                
                logger.debug(f"  â†’ Tact Time Snapshot: {len(tact_map)}ê±´ ì¡°íšŒ")
                
                # =============================================================
                # Step 4: Diff ê³„ì‚°
                # =============================================================
                deltas = []
                timestamp = datetime.utcnow()
                
                for equipment_id, status_info in status_map.items():
                    # ğŸ†• v2.0.0: equipment_id â†’ frontend_id ë³€í™˜
                    frontend_id = self._get_frontend_id(equipment_id)
                    if not frontend_id:
                        # ë§¤í•‘ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                        continue
                    
                    # ğŸ†• v2.1.0: ìƒì‚°ëŸ‰, Tact Time ì¡°íšŒ
                    production_count = prod_map.get(equipment_id, 0)
                    tact_time_seconds = tact_map.get(equipment_id)
                    
                    # Memory ì‚¬ìš©ìœ¨ ê³„ì‚°
                    memory_usage_percent = None
                    if status_info['memory_used_mb'] and status_info['memory_total_mb']:
                        memory_usage_percent = calculate_memory_usage_percent(
                            status_info['memory_used_mb'],
                            status_info['memory_total_mb']
                        )
                    
                    # ğŸ†• v2.1.0: í˜„ì¬ ìŠ¤ëƒ…ìƒ· ìƒì„± (ìƒì‚°ëŸ‰, Tact Time í¬í•¨)
                    current = EquipmentSnapshot(
                        frontend_id=frontend_id,
                        status=status_info['status'],
                        status_changed_at=status_info['status_changed_at'],
                        cpu_usage_percent=status_info['cpu_usage_percent'],
                        memory_usage_percent=memory_usage_percent,
                        production_count=production_count,           # ğŸ†• v2.1.0
                        tact_time_seconds=tact_time_seconds          # ğŸ†• v2.1.0
                    )
                    
                    # ì´ì „ ìŠ¤ëƒ…ìƒ· ì¡°íšŒ
                    previous = self._previous_state.get(frontend_id)
                    
                    if previous:
                        # Diff ê³„ì‚° (production_count, tact_time_seconds í¬í•¨ë¨)
                        changes = compute_delta(previous, current)
                        
                        if changes:
                            deltas.append(DeltaUpdate(
                                frontend_id=frontend_id,
                                changes=changes,
                                timestamp=timestamp
                            ))
                    
                    # ì´ì „ ìƒíƒœ ì—…ë°ì´íŠ¸
                    self._previous_state[frontend_id] = current
                
                if deltas:
                    logger.info(f"ğŸ”„ Detected {len(deltas)} changes (including production/tact_time)")
                
                return deltas
                
            except Exception as e:
                logger.error(f"âŒ Failed to compute diff: {e}", exc_info=True)
                return []
    
    # ========================================================================
    # í†µê³„ ê³„ì‚°
    # ========================================================================
    
    def calculate_stats(self, equipments: List[EquipmentData]) -> StatusStats:
        """
        ì„¤ë¹„ ëª©ë¡ì—ì„œ ìƒíƒœë³„ í†µê³„ ê³„ì‚°
        
        Args:
            equipments: EquipmentData ëª©ë¡
            
        Returns:
            StatusStats: ìƒíƒœë³„ ì¹´ìš´íŠ¸
        """
        return compute_status_stats(equipments)
    
    # ========================================================================
    # ìºì‹œ ê´€ë¦¬
    # ========================================================================
    
    def clear_cache(self):
        """In-Memory ìºì‹œ ì´ˆê¸°í™” (í…ŒìŠ¤íŠ¸/ë¦¬ì…‹ìš©)"""
        self._previous_state.clear()
        self._last_fetch_time = None
        logger.info("ğŸ—‘ï¸ UDS state cache cleared")
    
    def clear_mapping_cache(self):
        """
        ğŸ†• v2.0.0: ë§¤í•‘ ìºì‹œ ì´ˆê¸°í™”
        Site ë³€ê²½ ì‹œ ë˜ëŠ” ë§¤í•‘ ê°±ì‹  ì‹œ í˜¸ì¶œ
        """
        self._mapping_cache.clear()
        self._reverse_mapping.clear()
        self._current_site_id = None
        self._mapping_loaded_at = None
        logger.info("ğŸ—‘ï¸ UDS mapping cache cleared")
    
    def clear_all_caches(self):
        """
        ğŸ†• v2.0.0: ëª¨ë“  ìºì‹œ ì´ˆê¸°í™”
        """
        self.clear_cache()
        self.clear_mapping_cache()
        logger.info("ğŸ—‘ï¸ All UDS caches cleared")
    
    def reload_mapping(self, site_id: str = None):
        """
        ğŸ†• v2.0.0: ë§¤í•‘ ê°•ì œ ì¬ë¡œë“œ
        
        Args:
            site_id: Site ID (Noneì´ë©´ í˜„ì¬ Site)
        """
        target_site = site_id or self._current_site_id
        if target_site:
            self._load_mapping_config(target_site, force_reload=True)
    
    def get_cache_info(self) -> Dict[str, Any]:
        """ìºì‹œ ìƒíƒœ ì •ë³´"""
        return {
            "cached_count": len(self._previous_state),
            "last_fetch_time": self._last_fetch_time.isoformat() if self._last_fetch_time else None,
            "frontend_ids_sample": list(self._previous_state.keys())[:10],
            # ğŸ†• v2.0.0: ë§¤í•‘ ìºì‹œ ì •ë³´
            "mapping_cache_count": len(self._mapping_cache),
            "current_site_id": self._current_site_id,
            "mapping_loaded_at": self._mapping_loaded_at.isoformat() if self._mapping_loaded_at else None
        }
    
    def get_mapping_info(self) -> Dict[str, Any]:
        """
        ğŸ†• v2.0.0: ë§¤í•‘ ìƒíƒœ ì •ë³´
        """
        return {
            "site_id": self._current_site_id,
            "total_mappings": len(self._mapping_cache),
            "loaded_at": self._mapping_loaded_at.isoformat() if self._mapping_loaded_at else None,
            "equipment_ids_sample": list(self._mapping_cache.keys())[:10],
            "frontend_ids_sample": list(self._reverse_mapping.keys())[:10]
        }
    
    # ========================================================================
    # Private í—¬í¼ ë©”ì„œë“œ
    # ========================================================================
    
    def _row_to_equipment_data(
        self,
        row: Dict[str, Any],
        prod_map: Dict[int, int],  # ğŸ”§ v2.0.0: equipment_id ê¸°ë°˜
        tact_map: Dict[int, float]  # ğŸ”§ v2.0.0: equipment_id ê¸°ë°˜
    ) -> EquipmentData:
        """
        DB Row â†’ EquipmentData ë³€í™˜
        
        ğŸ”§ v2.0.0 ë³€ê²½ì‚¬í•­:
          - SQL ê²°ê³¼ì— FrontendId, GridRow, GridCol ì—†ìŒ
          - JSON ë§¤í•‘ì—ì„œ ê°€ì ¸ì™€ì„œ ë³‘í•©
          - ë§¤í•‘ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
        
        BATCH_EQUIPMENT_QUERY ì»¬ëŸ¼ ì¸ë±ìŠ¤ (v2.0.0):
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         0: EquipmentId      (core.Equipment)
         1: EquipmentName    (core.Equipment)
         2: LineName         (core.Equipment)
         3: Status           (log.EquipmentState)
         4: StatusChangedAt  (log.EquipmentState)
         5: ProductModel     (log.Lotinfo)
         6: LotId            (log.Lotinfo)
         7: LotStartTime     (log.Lotinfo)
         8: CpuUsagePercent  (log.EquipmentPCInfo)
         9: MemoryTotalMb    (log.EquipmentPCInfo)
        10: MemoryUsedMb     (log.EquipmentPCInfo)
        11: DisksTotalGb     (log.EquipmentPCInfo)
        12: DisksUsedGb      (log.EquipmentPCInfo)
        
        âŒ ì œê±°ë¨ (v2.0.0):
        13: GridRow          â†’ JSON ë§¤í•‘ì—ì„œ ê°€ì ¸ì˜´
        14: GridCol          â†’ JSON ë§¤í•‘ì—ì„œ ê°€ì ¸ì˜´
        15: FrontendId       â†’ JSON ë§¤í•‘ì—ì„œ ê°€ì ¸ì˜´
        """
        equipment_id = row['EquipmentId']
        
        # ===================================================================
        # ğŸ†• v2.0.0: JSON ë§¤í•‘ì—ì„œ FrontendId, GridRow, GridCol ê°€ì ¸ì˜¤ê¸°
        # ===================================================================
        mapping_info = self._get_mapping_info(equipment_id)
        
        if mapping_info:
            frontend_id = mapping_info.get('frontend_id')
            grid_row = mapping_info.get('grid_row', 0)
            grid_col = mapping_info.get('grid_col', 0)
        else:
            # ë§¤í•‘ ì—†ëŠ” ê²½ìš°: ê¸°ë³¸ê°’ ë˜ëŠ” equipment_id ê¸°ë°˜ ìƒì„±
            frontend_id = None
            grid_row = 0
            grid_col = 0
            logger.debug(f"âš ï¸ No mapping for equipment_id={equipment_id}")
        
        # FrontendId ì—†ìœ¼ë©´ equipment_id ê¸°ë°˜ ì„ì‹œ ID ìƒì„±
        if not frontend_id:
            # ì„ì‹œ ID: EQ-00-{equipment_id} í˜•ì‹
            frontend_id = f"EQ-00-{equipment_id:02d}"
        
        # Status Enum ë³€í™˜
        status_str = row.get('Status') or 'DISCONNECTED'
        try:
            status = EquipmentStatus(status_str)
        except ValueError:
            status = EquipmentStatus.DISCONNECTED
        
        # Memory/Disk ì‚¬ìš©ìœ¨ ê³„ì‚°
        memory_usage = None
        if row.get('MemoryTotalMb') and row.get('MemoryUsedMb'):
            memory_usage = calculate_memory_usage_percent(
                row['MemoryUsedMb'],
                row['MemoryTotalMb']
            )
        
        disk_usage = None
        if row.get('DisksTotalGb') and row.get('DisksUsedGb'):
            disk_usage = calculate_disk_usage_percent(
                row['DisksUsedGb'],
                row['DisksTotalGb']
            )
        
        # ğŸ”§ v2.0.0: ìƒì‚°ëŸ‰/Tact Timeì€ equipment_idë¡œ ì¡°íšŒ
        production_count = prod_map.get(equipment_id, 0)
        tact_time = tact_map.get(equipment_id)
        
        return EquipmentData(
            equipment_id=equipment_id,
            frontend_id=frontend_id,
            equipment_name=row.get('EquipmentName', ''),
            line_name=row.get('LineName', ''),
            status=status,
            status_changed_at=row.get('StatusChangedAt'),
            product_model=row.get('ProductModel'),
            lot_id=row.get('LotId'),
            lot_start_time=row.get('LotStartTime'),
            production_count=production_count,
            tact_time_seconds=tact_time,
            cpu_usage_percent=row.get('CpuUsagePercent'),
            memory_usage_percent=memory_usage,
            disk_usage_percent=disk_usage,
            grid_row=grid_row,
            grid_col=grid_col
        )
    
    def _update_previous_state(self, equipment: EquipmentData):
        """
        Diff ë¹„êµìš© ì´ì „ ìƒíƒœ ì—…ë°ì´íŠ¸
        
        ğŸ†• v2.1.0: production_count, tact_time_seconds í¬í•¨
        """
        self._previous_state[equipment.frontend_id] = EquipmentSnapshot(
            frontend_id=equipment.frontend_id,
            status=equipment.status.value if hasattr(equipment.status, 'value') else equipment.status,
            status_changed_at=equipment.status_changed_at,
            cpu_usage_percent=equipment.cpu_usage_percent,
            memory_usage_percent=equipment.memory_usage_percent,
            production_count=equipment.production_count,          # ğŸ†• v2.1.0
            tact_time_seconds=equipment.tact_time_seconds         # ğŸ†• v2.1.0
        )


# =============================================================================
# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
# =============================================================================
# ì•± ì „ì—­ì—ì„œ ë™ì¼ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© (In-Memory ìºì‹œ ê³µìœ )
uds_service = UDSService()