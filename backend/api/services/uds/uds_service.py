"""
uds_service.py
UDS ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì„œë¹„ìŠ¤
MSSQL ì§ì ‘ ì—°ê²° + JSON ë§¤í•‘ ë¡œë“œ + In-Memory ìƒíƒœ ìºì‹œ (Diffìš©)

@version 2.2.0
@description
- fetch_all_equipments: ë°°ì¹˜ ì¿¼ë¦¬ë¡œ ì „ì²´ ì„¤ë¹„ ì¡°íšŒ (117ê°œ)
- fetch_equipment_by_frontend_id: ë‹¨ì¼ ì„¤ë¹„ ì¡°íšŒ
- compute_diff: ì´ì „ ìƒíƒœì™€ í˜„ì¬ ìƒíƒœ ë¹„êµí•˜ì—¬ Delta ìƒì„±
- calculate_stats: ìƒíƒœë³„ í†µê³„ ê³„ì‚°

ğŸ”§ v2.2.0: core.Equipment ìŠ¤í‚¤ë§ˆ í˜¸í™˜ ìˆ˜ì •
- âŒ SiteId, LineId, IsActive ì»¬ëŸ¼ì€ DBì— ì¡´ì¬í•˜ì§€ ì•ŠìŒ!
- âœ… JSON ë§¤í•‘ íŒŒì¼ì˜ equipment_id ëª©ë¡ìœ¼ë¡œ IN ì ˆ í•„í„°ë§
- _get_equipment_ids_str(): ë§¤í•‘ì—ì„œ equipment_id ëª©ë¡ ì¶”ì¶œ
- ëª¨ë“  ì¿¼ë¦¬: WHERE e.EquipmentId IN ({equipment_ids})
- âš ï¸ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€

ğŸ”§ v2.1.2: connection_test.py í†µí•© (ê¸°ì¡´ ì‹œìŠ¤í…œ ì‚¬ìš©)
- multi_connection_manager.py ì œê±° â†’ connection_test.py ì‚¬ìš©
- connection_test.py ì—°ê²° ì •ë³´ë¡œ SQLAlchemy engine ì§ì ‘ ìƒì„±
- ê¸°ì¡´ ì¿¼ë¦¬ íŒŒì¼ (uds_queries.py) 100% í˜¸í™˜ ìœ ì§€
- âš ï¸ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€

ğŸ”§ v2.1.1: compute_diff ìë™ ì´ˆê¸°í™”
- _previous_stateê°€ ë¹„ì–´ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ fetch_all_equipments() í˜¸ì¶œ
- Status Watcher ì‹œì‘ ì‹œ Frontend ì—°ê²° ì—†ì´ë„ ì •ìƒ ë™ì‘
- âš ï¸ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€

ğŸ†• v2.1.0: ì‹¤ì‹œê°„ ìƒì‚°ëŸ‰/Tact Time Delta ì—…ë°ì´íŠ¸
- compute_diff(): PRODUCTION_SNAPSHOT_QUERY, BATCH_TACT_TIME_QUERY ì¶”ê°€
- EquipmentSnapshotì— production_count, tact_time_seconds í¬í•¨
- Deltaì— ìƒì‚°ëŸ‰/Tact Time ë³€ê²½ì‚¬í•­ ì‹¤ì‹œê°„ ë°˜ì˜
- âš ï¸ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€

ğŸ†• v2.0.0: JSON ë§¤í•‘ í†µí•©
- _load_mapping_config(): Siteë³„ JSON ë§¤í•‘ íŒŒì¼ ë¡œë“œ
- _merge_with_mapping(): SQL ê²°ê³¼ + JSON ë§¤í•‘ ë³‘í•©
- _parse_frontend_id(): FrontendId â†’ (GridRow, GridCol) íŒŒì‹±
- equipment_id â†” frontend_id ì—­ë§¤í•‘ í…Œì´ë¸” ê´€ë¦¬

@changelog
- v2.2.0: ğŸ”§ core.Equipment ìŠ¤í‚¤ë§ˆ í˜¸í™˜ ìˆ˜ì • (2026-01-21)
          - âŒ SiteId, LineId, IsActive ì»¬ëŸ¼ì€ DBì— ì¡´ì¬í•˜ì§€ ì•ŠìŒ!
          - âœ… JSON ë§¤í•‘ì˜ equipment_id ëª©ë¡ìœ¼ë¡œ IN ì ˆ í•„í„°ë§
          - _get_equipment_ids_str() í—¬í¼ ë©”ì„œë“œ ì¶”ê°€
          - fetch_all_equipments(): ì¿¼ë¦¬ì— equipment_ids ì£¼ì…
          - compute_diff(): ì¿¼ë¦¬ì— equipment_ids ì£¼ì…
          - âš ï¸ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€
- v2.1.2: ğŸ”§ connection_test.py í†µí•© (2026-01-21)
          - multi_connection_manager.py ì˜ì¡´ì„± ì œê±°
          - connection_test.py ì—°ê²° ì •ë³´ + SQLAlchemy engine ì§ì ‘ ìƒì„±
          - ê¸°ì¡´ ì¿¼ë¦¬ (:param í˜•ì‹) 100% í˜¸í™˜
          - _engines ìºì‹œë¡œ ì—°ê²° ì¬ì‚¬ìš©
          - âš ï¸ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€
- v2.1.1: ğŸ”§ compute_diff ìë™ ì´ˆê¸°í™” (2026-01-21)
          - _previous_state ë¹„ì–´ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ fetch_all_equipments() í˜¸ì¶œ
          - Status Watcher ì‹œì‘ ì‹œ "No previous state" ê²½ê³  í•´ê²°
          - Frontend ì—°ê²° ì „ì—ë„ Watcher ì •ìƒ ë™ì‘
          - âš ï¸ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€
- v2.1.0: ğŸ†• ì‹¤ì‹œê°„ ìƒì‚°ëŸ‰/Tact Time Delta ì—…ë°ì´íŠ¸ (2026-01-21)
          - compute_diff()ì—ì„œ PRODUCTION_SNAPSHOT_QUERY ì‹¤í–‰
          - compute_diff()ì—ì„œ BATCH_TACT_TIME_QUERY ì‹¤í–‰
          - EquipmentSnapshotì— production_count, tact_time_seconds í•„ë“œ ì‚¬ìš©
          - Deltaì— ìƒì‚°ëŸ‰/Tact Time ë³€ê²½ ì‹œ í¬í•¨
          - âš ï¸ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€
- v2.0.0: ğŸ”§ JSON ë§¤í•‘ í†µí•© (2026-01-21)
          - core.EquipmentMapping í…Œì´ë¸” ì œê±° (DBì— ì—†ìŒ)
          - JSON íŒŒì¼ì—ì„œ ë§¤í•‘ ì •ë³´ ë¡œë“œ
          - SQL ê²°ê³¼ì™€ ë§¤í•‘ ë³‘í•© ë¡œì§ ì¶”ê°€
          - equipment_id â†” frontend_id ì–‘ë°©í–¥ ë§¤í•‘
          - Site ë³€ê²½ ì‹œ ë§¤í•‘ ìºì‹œ ìë™ ê°±ì‹ 
          - âš ï¸ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€
- v1.0.0: ì´ˆê¸° ë²„ì „
          - MSSQL ì§ì ‘ ì—°ê²° (SQLAlchemy sync session)
          - In-Memory ìºì‹œë¡œ Diff ë¹„êµ
          - ë°°ì¹˜/ë‹¨ì¼ ì¿¼ë¦¬ ì§€ì›
          - âš ï¸ WITH (NOLOCK) ëª¨ë“  ì¿¼ë¦¬ì— ì ìš©ë¨

@dependencies
- sqlalchemy
- pyodbc (via connection_test.py)
- models/uds/uds_models.py
- services/uds/uds_queries.py
- database/connection_test.py

ğŸ“ ìœ„ì¹˜: backend/api/services/uds/uds_service.py
ì‘ì„±ì¼: 2026-01-20
ìˆ˜ì •ì¼: 2026-01-21
"""

from typing import List, Optional, Dict, Any, Tuple
import logging
import json
import os
from datetime import datetime
from contextlib import contextmanager
from urllib.parse import quote_plus

from sqlalchemy import create_engine, text
from sqlalchemy.orm import Session, sessionmaker
from sqlalchemy.pool import QueuePool

# UDS ëª¨ë¸ Import
from ...models.uds.uds_models import (
    EquipmentData,
    EquipmentStatus,
    StatusStats,
    DeltaUpdate,
    EquipmentSnapshot,
    compute_status_stats,
    compute_delta
)

# UDS ì¿¼ë¦¬ Import
# ğŸ†• v2.1.0: PRODUCTION_SNAPSHOT_QUERY ì¶”ê°€
from .uds_queries import (
    BATCH_EQUIPMENT_QUERY,
    SINGLE_EQUIPMENT_QUERY,
    PRODUCTION_COUNT_QUERY,
    PRODUCTION_SNAPSHOT_QUERY,  # ğŸ†• v2.1.0
    BATCH_TACT_TIME_QUERY,
    STATUS_SNAPSHOT_QUERY,
    ALARM_REPEAT_COUNT_QUERY,    # âœ… ì¶”ê°€!
    STATE_HISTORY_QUERY,         # ğŸ†• v2.4.0 ì¶”ê°€!
    calculate_memory_usage_percent,
    calculate_disk_usage_percent,
    parse_frontend_id,  # ğŸ†• v2.0.0
    generate_frontend_id  # ğŸ†• v2.0.0
)

# ğŸ”§ v2.1.2: ê¸°ì¡´ connection_test.py ì‚¬ìš© (multi_connection_manager ì œê±°)
from ...database.connection_test import get_connection_manager

logger = logging.getLogger(__name__)


# =============================================================================
# ğŸ†• v2.0.0: ë§¤í•‘ ê´€ë ¨ ìƒìˆ˜
# =============================================================================
MAPPING_CONFIG_DIR = "config/site_mappings"
DEFAULT_GRID_ROWS = 26
DEFAULT_GRID_COLS = 6


class UDSService:
    """
    Unified Data Store ì„œë¹„ìŠ¤
    
    [ì£¼ìš” ê¸°ëŠ¥]
    1. ì „ì²´ ì„¤ë¹„ ë°°ì¹˜ ì¡°íšŒ (ì´ˆê¸° ë¡œë“œ)
    2. ë‹¨ì¼ ì„¤ë¹„ ì¡°íšŒ (ìºì‹œ ë¯¸ìŠ¤ ì‹œ)
    3. Diff ê°ì§€ ë° Delta ìƒì„± (10ì´ˆ ì£¼ê¸°)
    4. ìƒíƒœë³„ í†µê³„ ê³„ì‚°
    
    ğŸ†• v2.1.0: ì‹¤ì‹œê°„ ìƒì‚°ëŸ‰/Tact Time Delta
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ compute_diff()ì—ì„œ 3ê°œ ì¿¼ë¦¬ ì‹¤í–‰:                             â”‚
    â”‚   1. STATUS_SNAPSHOT_QUERY - ìƒíƒœ/CPU/Memory                 â”‚
    â”‚   2. PRODUCTION_SNAPSHOT_QUERY - ìƒì‚°ëŸ‰ (ì˜¤ëŠ˜ ê¸°ì¤€)          â”‚
    â”‚   3. BATCH_TACT_TIME_QUERY - Tact Time (ìµœê·¼ ì‚¬ì´í´)         â”‚
    â”‚                                                              â”‚
    â”‚ Deltaì— í¬í•¨ë˜ëŠ” í•„ë“œ:                                        â”‚
    â”‚   - status, status_changed_at                                â”‚
    â”‚   - cpu_usage_percent, memory_usage_percent                  â”‚
    â”‚   - production_count (ğŸ†• v2.1.0)                             â”‚
    â”‚   - tact_time_seconds (ğŸ†• v2.1.0)                            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ğŸ†• v2.0.0: JSON ë§¤í•‘ í†µí•©
    5. Siteë³„ JSON ë§¤í•‘ íŒŒì¼ ë¡œë“œ
    6. SQL ê²°ê³¼ + ë§¤í•‘ ë³‘í•©
    7. equipment_id â†” frontend_id ì–‘ë°©í–¥ ì¡°íšŒ
    
    [In-Memory ìºì‹œ]
    - _previous_state: Dict[frontend_id, EquipmentSnapshot]
    - Diff ë¹„êµìš©ìœ¼ë¡œë§Œ ì‚¬ìš© (Frontendê°€ ë©”ì¸ ìºì‹œ)
    
    ğŸ†• v2.0.0: ë§¤í•‘ ìºì‹œ
    - _mapping_cache: Dict[equipment_id, MappingItem]
    - _reverse_mapping: Dict[frontend_id, equipment_id]
    - _current_site_id: í˜„ì¬ ë¡œë“œëœ Site ID
    
    [DB ì—°ê²°]
    - MultiConnectionManager ì‚¬ìš© (Site DB ë™ì  ì—°ê²°)
    - ëª¨ë“  ì¿¼ë¦¬ WITH (NOLOCK) ì ìš©
    """
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        # Diff ë¹„êµìš© In-Memory ìƒíƒœ ìºì‹œ
        self._previous_state: Dict[str, EquipmentSnapshot] = {}
        
        # ë§ˆì§€ë§‰ ì¡°íšŒ ì‹œê°„ (ë””ë²„ê¹…ìš©)
        self._last_fetch_time: Optional[datetime] = None
        
        # ===================================================================
        # ğŸ†• v2.1.2: SQLAlchemy ì—”ì§„ ìºì‹œ
        # ===================================================================
        # {site_name}_{db_name} â†’ SQLAlchemy Engine
        self._engines: Dict[str, Any] = {}
        self._session_factories: Dict[str, sessionmaker] = {}
        
        # ===================================================================
        # ğŸ†• v2.0.0: ë§¤í•‘ ìºì‹œ
        # ===================================================================
        # equipment_id â†’ {frontend_id, equipment_name, grid_row, grid_col, ...}
        self._mapping_cache: Dict[int, Dict[str, Any]] = {}
        
        # frontend_id â†’ equipment_id (ì—­ë§¤í•‘)
        self._reverse_mapping: Dict[str, int] = {}
        
        # í˜„ì¬ ë¡œë“œëœ Site ID
        self._current_site_id: Optional[str] = None
        
        # ë§¤í•‘ ë¡œë“œ ì‹œê°„
        self._mapping_loaded_at: Optional[datetime] = None

        # ğŸ†• Remote Alarm Codes ìºì‹œ
        self._remote_alarm_codes: set = set()
        self._remote_alarm_codes_loaded: bool = False
        
        logger.info("ğŸš€ UDSService initialized (v2.1.2 - connection_test.py í†µí•©)")
    
    # ========================================================================
    # Context Manager: DB Session (ğŸ”§ v2.1.2 connection_test.py í†µí•©)
    # ========================================================================
    
    def _get_or_create_engine(self, site_name: str, db_name: str):
        """
        SQLAlchemy ì—”ì§„ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        
        ğŸ†• v2.1.2: connection_test.py ì—°ê²° ì •ë³´ë¡œ SQLAlchemy engine ìƒì„±
        
        Args:
            site_name: ì‚¬ì´íŠ¸ ì´ë¦„ (ì˜ˆ: korea_site1)
            db_name: DB ì´ë¦„ (ì˜ˆ: SherlockSky)
            
        Returns:
            SQLAlchemy Engine
        """
        cache_key = f"{site_name}_{db_name}"
        
        # ìºì‹œì— ìˆìœ¼ë©´ ë°˜í™˜
        if cache_key in self._engines:
            return self._engines[cache_key]
        
        # connection_test.pyì—ì„œ ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        manager = get_connection_manager()
        
        if site_name not in manager.databases_config:
            raise ConnectionError(f"Site not found in config: {site_name}")
        
        site_config = manager.databases_config[site_name]
        databases = site_config.get('databases', {})
        
        if db_name not in databases:
            raise ConnectionError(f"Database not found: {site_name}/{db_name}")
        
        # ì—°ê²° URL ìƒì„±
        db_type = site_config.get('type', 'mssql').lower()
        host = site_config.get('host')
        port = site_config.get('port', 1433)
        user = site_config.get('user')
        password = site_config.get('password')
        database = databases[db_name]
        
        if db_type == 'mssql':
            # ODBC ë“œë¼ì´ë²„ ê°ì§€
            driver = self._get_mssql_driver()
            driver_encoded = quote_plus(driver)
            
            connection_url = (
                f"mssql+pyodbc://{user}:{password}@"
                f"{host}:{port}/{database}"
                f"?driver={driver_encoded}"
                f"&TrustServerCertificate=yes"
                f"&Encrypt=yes"
            )
        elif db_type == 'postgresql':
            connection_url = (
                f"postgresql://{user}:{password}@"
                f"{host}:{port}/{database}"
            )
        else:
            raise ValueError(f"Unsupported database type: {db_type}")
        
        # ì—”ì§„ ìƒì„±
        engine = create_engine(
            connection_url,
            poolclass=QueuePool,
            pool_size=5,
            max_overflow=10,
            pool_timeout=30,
            pool_recycle=3600,
            pool_pre_ping=True
        )
        
        # ìºì‹œì— ì €ì¥
        self._engines[cache_key] = engine
        
        # ì„¸ì…˜ íŒ©í† ë¦¬ë„ ìƒì„±
        self._session_factories[cache_key] = sessionmaker(
            bind=engine,
            autocommit=False,
            autoflush=False
        )
        
        logger.info(f"âœ… Created SQLAlchemy engine: {site_name}/{db_name}")
        
        return engine
    
    def _get_mssql_driver(self) -> str:
        """ì„¤ì¹˜ëœ MSSQL ODBC ë“œë¼ì´ë²„ ê°ì§€"""
        try:
            import pyodbc
            drivers = pyodbc.drivers()
            
            preferred_drivers = [
                'ODBC Driver 18 for SQL Server',
                'ODBC Driver 17 for SQL Server',
                'ODBC Driver 13 for SQL Server',
                'SQL Server Native Client 11.0',
                'SQL Server'
            ]
            
            for driver in preferred_drivers:
                if driver in drivers:
                    return driver
            
            for driver in drivers:
                if 'SQL Server' in driver:
                    return driver
            
            return 'ODBC Driver 17 for SQL Server'
            
        except ImportError:
            return 'ODBC Driver 17 for SQL Server'
    
    @contextmanager
    def _get_session(self, site_id: str = None, db_name: str = None):
        """
        DB Session Context Manager
        
        ğŸ”§ v2.1.2: connection_test.py ì—°ê²° ì •ë³´ë¡œ SQLAlchemy session ìƒì„±
        
        Args:
            site_id: Site ID (Noneì´ë©´ ì—°ê²°ëœ ì‚¬ì´íŠ¸ì—ì„œ ê°€ì ¸ì˜´)
            db_name: DB ì´ë¦„ (Noneì´ë©´ ì—°ê²°ëœ ì‚¬ì´íŠ¸ì—ì„œ ê°€ì ¸ì˜´)
            
        Yields:
            Session: SQLAlchemy ì„¸ì…˜
        """
        # ğŸ”§ v2.1.1: íŒŒë¼ë¯¸í„°ê°€ Noneì´ë©´ ì—°ê²°ëœ ì‚¬ì´íŠ¸ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        if site_id is None or db_name is None:
            connected_sites = self._get_connected_sites()
            if connected_sites:
                first_site_id = list(connected_sites.keys())[0]
                site_info = connected_sites[first_site_id]
                if site_id is None:
                    site_id = site_info.get('site_name')
                if db_name is None:
                    db_name = site_info.get('db_name')
                logger.debug(f"Using connected site for session: {site_id}/{db_name}")
        
        if site_id is None or db_name is None:
            raise ConnectionError("No site connected. Please connect via /api/connections/connect")
        
        # ì—”ì§„ ë° ì„¸ì…˜ íŒ©í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
        cache_key = f"{site_id}_{db_name}"
        
        if cache_key not in self._session_factories:
            self._get_or_create_engine(site_id, db_name)
        
        factory = self._session_factories[cache_key]
        session = factory()
        
        try:
            yield session
        finally:
            session.close()
    
    # ========================================================================
    # ğŸ†• v2.0.0: JSON ë§¤í•‘ ë¡œë“œ
    # ========================================================================
    
    def _get_mapping_file_path(self, site_id: str) -> str:
        """
        Siteë³„ ë§¤í•‘ íŒŒì¼ ê²½ë¡œ
        
        Args:
            site_id: "korea_site1_line1" í˜•ì‹
            
        Returns:
            "config/site_mappings/equipment_mapping_korea_site1_line1.json"
        """
        return os.path.join(MAPPING_CONFIG_DIR, f"equipment_mapping_{site_id}.json")
    
    def _load_mapping_config(self, site_id: str, force_reload: bool = False) -> bool:
        """
        Siteë³„ JSON ë§¤í•‘ íŒŒì¼ ë¡œë“œ
        
        ğŸ†• v2.0.0: core.EquipmentMapping í…Œì´ë¸” ëŒ€ì‹  JSON íŒŒì¼ ì‚¬ìš©
        
        Args:
            site_id: Site ID (ì˜ˆ: "korea_site1_line1")
            force_reload: ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€
            
        Returns:
            bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
            
        Note:
            - ìºì‹œëœ Site IDì™€ ë™ì¼í•˜ë©´ ì¬ë¡œë“œ ì•ˆ í•¨ (force_reload=False)
            - íŒŒì¼ ì—†ìœ¼ë©´ ë¹ˆ ë§¤í•‘ìœ¼ë¡œ ì´ˆê¸°í™”
        """
        # ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ìŠ¤í‚µ
        if not force_reload and self._current_site_id == site_id:
            return True
        
        file_path = self._get_mapping_file_path(site_id)
        
        logger.info(f"ğŸ“‚ Loading mapping config: {file_path}")
        
        # ìºì‹œ ì´ˆê¸°í™”
        self._mapping_cache.clear()
        self._reverse_mapping.clear()
        
        if not os.path.exists(file_path):
            logger.warning(f"âš ï¸ Mapping file not found: {file_path}")
            self._current_site_id = site_id
            self._mapping_loaded_at = datetime.utcnow()
            return False
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            mappings = data.get("mappings", {})
            
            for frontend_id, item in mappings.items():
                equipment_id = item.get("equipment_id")
                if equipment_id is None:
                    continue
                
                # equipment_id â†’ mapping info
                self._mapping_cache[equipment_id] = {
                    "frontend_id": frontend_id,
                    "equipment_name": item.get("equipment_name", ""),
                    "equipment_code": item.get("equipment_code"),
                    "line_name": item.get("line_name"),
                    "grid_row": None,  # íŒŒì‹±ìœ¼ë¡œ ê³„ì‚°
                    "grid_col": None
                }
                
                # GridRow, GridCol íŒŒì‹±
                grid_row, grid_col = parse_frontend_id(frontend_id)
                self._mapping_cache[equipment_id]["grid_row"] = grid_row
                self._mapping_cache[equipment_id]["grid_col"] = grid_col
                
                # ì—­ë§¤í•‘: frontend_id â†’ equipment_id
                self._reverse_mapping[frontend_id] = equipment_id
            
            self._current_site_id = site_id
            self._mapping_loaded_at = datetime.utcnow()
            
            logger.info(f"âœ… Loaded {len(self._mapping_cache)} mappings for {site_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to load mapping config: {e}", exc_info=True)
            self._current_site_id = site_id
            self._mapping_loaded_at = datetime.utcnow()
            return False
    
    def _get_frontend_id(self, equipment_id: int) -> Optional[str]:
        """
        equipment_id â†’ frontend_id ë³€í™˜
        
        Args:
            equipment_id: DB Equipment ID
            
        Returns:
            frontend_id ë˜ëŠ” None (ë§¤í•‘ ì—†ìŒ)
        """
        mapping = self._mapping_cache.get(equipment_id)
        if mapping:
            return mapping.get("frontend_id")
        return None
    
    def _get_equipment_id(self, frontend_id: str) -> Optional[int]:
        """
        frontend_id â†’ equipment_id ë³€í™˜
        
        Args:
            frontend_id: Frontend ID (ì˜ˆ: "EQ-17-03")
            
        Returns:
            equipment_id ë˜ëŠ” None (ë§¤í•‘ ì—†ìŒ)
        """
        return self._reverse_mapping.get(frontend_id)
    
    def _get_mapping_info(self, equipment_id: int) -> Optional[Dict[str, Any]]:
        """
        equipment_idë¡œ ì „ì²´ ë§¤í•‘ ì •ë³´ ì¡°íšŒ
        
        Args:
            equipment_id: DB Equipment ID
            
        Returns:
            ë§¤í•‘ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
            {
                "frontend_id": "EQ-17-03",
                "equipment_name": "CVDF-001",
                "grid_row": 17,
                "grid_col": 3,
                ...
            }
        """
        return self._mapping_cache.get(equipment_id)
    
    def _get_equipment_ids_str(self) -> str:
        """
        ğŸ†• v2.2.0: ë§¤í•‘ ìºì‹œì—ì„œ equipment_id ëª©ë¡ ì¶”ì¶œ
        
        IN ì ˆì— ì‚¬ìš©í•  ë¬¸ìì—´ í˜•íƒœë¡œ ë°˜í™˜
        
        Returns:
            "1, 2, 3, ..., 117" í˜•ì‹ì˜ ë¬¸ìì—´
            
        Raises:
            ValueError: ë§¤í•‘ì´ ë¹„ì–´ìˆëŠ” ê²½ìš°
            
        Example:
            >>> ids_str = self._get_equipment_ids_str()
            >>> query = BATCH_EQUIPMENT_QUERY.format(equipment_ids=ids_str)
        """
        if not self._mapping_cache:
            raise ValueError("Mapping cache is empty. Load mapping first.")
        
        equipment_ids = sorted(self._mapping_cache.keys())
        return ", ".join(str(eq_id) for eq_id in equipment_ids)
    
    def _get_connected_sites(self) -> Dict[str, Any]:
        """
        ğŸ†• v2.1.1: í˜„ì¬ ì—°ê²°ëœ ì‚¬ì´íŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        (equipment_mapping_v2.pyì˜ get_connected_sites()ì™€ ë™ì¼)
        """
        try:
            from ...routers.connection_manager import _connected_sites
            return _connected_sites
        except ImportError as e:
            logger.warning(f"âš ï¸ Could not import _connected_sites: {e}")
            return {}
        except Exception as e:
            logger.error(f"âŒ Error getting connected sites: {e}")
            return {}
    
    def _derive_site_id_from_connection(self, db_site: str = None, db_name: str = None) -> Optional[str]:
        """
        ì—°ê²° ì •ë³´ì—ì„œ Site ID ìœ ë„
        
        ğŸ”§ v2.1.1: ê¸°ì¡´ equipment_mapping_v2.py ë¡œì§ê³¼ ë™ì¼í•˜ê²Œ ìˆ˜ì •
                   1ìˆœìœ„: í˜„ì¬ ì—°ê²°ëœ ì‚¬ì´íŠ¸ì—ì„œ ê°€ì ¸ì˜¤ê¸° (_connected_sites)
                   2ìˆœìœ„: íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ëœ ê°’ ì‚¬ìš©
                   âŒ 3ìˆœìœ„ ì œê±°: ì—°ê²° ì—†ìœ¼ë©´ None ë°˜í™˜ (default fallback ì•ˆ í•¨)
        
        Args:
            db_site: Site í‚¤ (ì˜ˆ: "korea_site1")
            db_name: DB ì´ë¦„ (ì˜ˆ: "line1")
            
        Returns:
            Site ID (ì˜ˆ: "korea_site1_line1") ë˜ëŠ” None (ì—°ê²° ì—†ìŒ)
        """
        # 1ìˆœìœ„: í˜„ì¬ ì—°ê²°ëœ ì‚¬ì´íŠ¸ì—ì„œ ê°€ì ¸ì˜¤ê¸° (equipment_mapping_v2.py ë°©ì‹)
        connected_sites = self._get_connected_sites()
        
        if connected_sites:
            site_id = list(connected_sites.keys())[0]
            logger.debug(f"âœ… Using connected site: {site_id}")
            return site_id
        
        # 2ìˆœìœ„: íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ëœ ê°’ ì‚¬ìš©
        if db_site and db_name:
            site_id = f"{db_site}_{db_name}"
            logger.debug(f"ğŸ“Œ Using parameter site: {site_id}")
            return site_id
        
        # ğŸ”§ v2.1.1: ì—°ê²°ëœ ì‚¬ì´íŠ¸ ì—†ìœ¼ë©´ None ë°˜í™˜ (default fallback ì•ˆ í•¨!)
        logger.debug("â³ No connected site yet, waiting...")
        return None
    
    # ========================================================================
    # ë°°ì¹˜ ì¡°íšŒ: ì „ì²´ ì„¤ë¹„ ì´ˆê¸° ë¡œë“œ
    # ========================================================================
    
    def fetch_all_equipments(
        self,
        site_id: int = 1,
        line_id: int = 1,
        db_site: str = None,
        db_name: str = None
    ) -> List[EquipmentData]:
        """
        ì „ì²´ ì„¤ë¹„ ë°°ì¹˜ ì¡°íšŒ (ì´ˆê¸° ë¡œë“œ)
        
        GET /api/uds/initial ì—”ë“œí¬ì¸íŠ¸ì—ì„œ í˜¸ì¶œ.
        117ê°œ ì„¤ë¹„ ë°ì´í„°ë¥¼ í•œ ë²ˆì˜ ë°°ì¹˜ ì¿¼ë¦¬ë¡œ ì¡°íšŒ.
        
        ğŸ”§ v2.0.0 ë³€ê²½ì‚¬í•­:
          - SQL ì¿¼ë¦¬ì—ì„œ core.EquipmentMapping JOIN ì œê±°
          - JSON ë§¤í•‘ íŒŒì¼ ë¡œë“œ í›„ SQL ê²°ê³¼ì™€ ë³‘í•©
          - âš ï¸ API ì‘ë‹µ í˜•ì‹ 100% ìœ ì§€ (í•˜ìœ„ í˜¸í™˜)
        
        Args:
            site_id: Factory Site ID (WHERE ì¡°ê±´)
            line_id: Factory Line ID (WHERE ì¡°ê±´)
            db_site: MultiConnectionManager Site í‚¤ (ê¸°ë³¸ê°’ ì‚¬ìš©)
            db_name: DB ì´ë¦„ (ê¸°ë³¸ê°’ ì‚¬ìš©)
            
        Returns:
            List[EquipmentData]: ì „ì²´ ì„¤ë¹„ ë°ì´í„° ëª©ë¡
            
        Raises:
            Exception: DB ì—°ê²° ë˜ëŠ” ì¿¼ë¦¬ ì‹¤íŒ¨ ì‹œ
        """
        logger.info(f"ğŸ“¡ Fetching all equipments (site_id={site_id}, line_id={line_id})")
        start_time = datetime.utcnow()
        
        # ===================================================================
        # ğŸ”§ v2.1.1: ì—°ê²°ëœ ì‚¬ì´íŠ¸ í™•ì¸ (ì‚¬ì´íŠ¸ ì—°ê²° ì „ì´ë©´ ì—ëŸ¬)
        # ===================================================================
        mapping_site_id = self._derive_site_id_from_connection(db_site, db_name)
        
        if mapping_site_id is None:
            logger.warning("âš ï¸ No site connected yet, cannot fetch equipments")
            raise ConnectionError("No site connected. Please connect to a site first via /api/connections/connect")
        
        # ===================================================================
        # ğŸ†• v2.0.0: ë§¤í•‘ íŒŒì¼ ë¡œë“œ (Site ë³€ê²½ ì‹œ ìë™ ê°±ì‹ )
        # ===================================================================
        self._load_mapping_config(mapping_site_id)
        
        # ===================================================================
        # ğŸ†• v2.2.0: ë§¤í•‘ì—ì„œ equipment_id ëª©ë¡ ì¶”ì¶œ
        # ===================================================================
        try:
            equipment_ids_str = self._get_equipment_ids_str()
            logger.info(f"  â†’ ë§¤í•‘ ê¸°ì¤€ equipment_ids: {len(self._mapping_cache)}ê°œ")
        except ValueError as e:
            logger.error(f"âŒ Failed to get equipment IDs: {e}")
            raise
        
        with self._get_session(db_site, db_name) as session:
            try:
                # =============================================================
                # Step 1: ê¸°ë³¸ ì„¤ë¹„ ì •ë³´ ë°°ì¹˜ ì¡°íšŒ
                # ğŸ”§ v2.2.0: IN ì ˆë¡œ ë§¤í•‘ëœ ì„¤ë¹„ë§Œ ì¡°íšŒ
                # =============================================================
                query = BATCH_EQUIPMENT_QUERY.format(equipment_ids=equipment_ids_str)
                result = session.execute(text(query))
                rows = result.fetchall()
                columns = result.keys()
                
                logger.info(f"  â†’ ê¸°ë³¸ ì¿¼ë¦¬: {len(rows)}ê±´ ì¡°íšŒ")
                
                # =============================================================
                # Step 2: ìƒì‚°ëŸ‰ ë°°ì¹˜ ì¡°íšŒ
                # ğŸ”§ v2.2.0: IN ì ˆë¡œ ë§¤í•‘ëœ ì„¤ë¹„ë§Œ ì¡°íšŒ
                # =============================================================
                prod_query = PRODUCTION_COUNT_QUERY.format(equipment_ids=equipment_ids_str)
                prod_result = session.execute(text(prod_query))
                prod_rows = prod_result.fetchall()
                
                # ğŸ”§ v2.0.0: equipment_id ê¸°ë°˜ ë§µ (ê¸°ì¡´: frontend_id)
                # Column Index: [0] EquipmentId, [1] ProductionCount
                prod_map = {row[0]: row[1] for row in prod_rows}
                
                logger.info(f"  â†’ ìƒì‚°ëŸ‰ ì¿¼ë¦¬: {len(prod_map)}ê±´ ì¡°íšŒ")
                
                # =============================================================
                # Step 3: Tact Time ë°°ì¹˜ ì¡°íšŒ
                # ğŸ”§ v2.2.0: IN ì ˆë¡œ ë§¤í•‘ëœ ì„¤ë¹„ë§Œ ì¡°íšŒ
                # =============================================================
                tact_query = BATCH_TACT_TIME_QUERY.format(equipment_ids=equipment_ids_str)
                tact_result = session.execute(text(tact_query))
                tact_rows = tact_result.fetchall()
                
                # ğŸ”§ v2.0.0: equipment_id ê¸°ë°˜ ë§µ (ê¸°ì¡´: frontend_id)
                # Column Index: [0] EquipmentId, [1] TactTimeSeconds
                tact_map = {row[0]: row[1] for row in tact_rows}
                
                logger.info(f"  â†’ Tact Time ì¿¼ë¦¬: {len(tact_map)}ê±´ ì¡°íšŒ")

                # =============================================================
                # Step 3.5: ì•ŒëŒ ë°˜ë³µ íšŸìˆ˜ ë°°ì¹˜ ì¡°íšŒ (âœ… ì¶”ê°€!)
                # =============================================================
                alarm_repeat_query = ALARM_REPEAT_COUNT_QUERY.format(equipment_ids=equipment_ids_str)
                alarm_repeat_result = session.execute(text(alarm_repeat_query))
                alarm_repeat_rows = alarm_repeat_result.fetchall()
                
                # equipment_id â†’ alarm_repeat_count ë§µ
                # Column Index: [0] EquipmentId, [1] AlarmCode, [2] AlarmRepeatCount
                alarm_repeat_map = {row[0]: row[2] for row in alarm_repeat_rows}
                
                logger.info(f"  â†’ ì•ŒëŒ ë°˜ë³µ íšŸìˆ˜ ì¿¼ë¦¬: {len(alarm_repeat_map)}ê±´ ì¡°íšŒ")

                # =============================================================
                # Step 3.6: ìƒíƒœ íˆìŠ¤í† ë¦¬ ë°°ì¹˜ ì¡°íšŒ (ğŸ†• v2.4.0)
                # =============================================================
                history_query = STATE_HISTORY_QUERY.format(equipment_ids=equipment_ids_str)
                history_result = session.execute(text(history_query))
                history_rows = history_result.fetchall()
                
                # equipment_id â†’ [ìƒíƒœ íˆìŠ¤í† ë¦¬ ë¦¬ìŠ¤íŠ¸] ë§µ
                # Column Index: [0] EquipmentId, [1] Status, [2] OccurredAtUtc
                state_history_map = {}
                for row in history_rows:
                    eq_id = row[0]
                    if eq_id not in state_history_map:
                        state_history_map[eq_id] = []
                    state_history_map[eq_id].append({
                        'status': row[1],
                        'timestamp': row[2].isoformat() if row[2] else None
                    })
                
                logger.info(f"  â†’ ìƒíƒœ íˆìŠ¤í† ë¦¬ ì¿¼ë¦¬: {len(state_history_map)}ê±´ ì¡°íšŒ")
                
                # =============================================================
                # Step 4: EquipmentData ë³€í™˜ + ë§¤í•‘ ë³‘í•©
                # ğŸ†• v2.0.0: SQL ê²°ê³¼ + JSON ë§¤í•‘ ë³‘í•©
                # =============================================================
                equipments = []
                for row in rows:
                    row_dict = dict(zip(columns, row))
                    equipment = self._row_to_equipment_data(
                        row_dict, 
                        prod_map, 
                        tact_map,
                        alarm_repeat_map,    # âœ… ì¶”ê°€!
                        state_history_map    # ğŸ†• v2.4.0 ì¶”ê°€!
                    )
                    equipments.append(equipment)
                    
                    # In-Memory ìºì‹œ ì—…ë°ì´íŠ¸ (Diffìš©)
                    self._update_previous_state(equipment)
                
                # ì¡°íšŒ ì‹œê°„ ê¸°ë¡
                self._last_fetch_time = datetime.utcnow()
                elapsed_ms = (self._last_fetch_time - start_time).total_seconds() * 1000
                
                logger.info(f"âœ… Loaded {len(equipments)} equipments in {elapsed_ms:.1f}ms")
                return equipments
                
            except Exception as e:
                logger.error(f"âŒ Failed to fetch equipments: {e}", exc_info=True)
                raise
    
    # ========================================================================
    # ë‹¨ì¼ ì¡°íšŒ: Frontend IDë¡œ ì„¤ë¹„ ì¡°íšŒ
    # ========================================================================
    
    def fetch_equipment_by_frontend_id(
        self,
        frontend_id: str,
        db_site: str = None,
        db_name: str = None
    ) -> Optional[EquipmentData]:
        """
        ë‹¨ì¼ ì„¤ë¹„ ì¡°íšŒ
        
        GET /api/uds/equipment/{frontend_id} ì—”ë“œí¬ì¸íŠ¸ì—ì„œ í˜¸ì¶œ.
        âš ï¸ FrontendëŠ” UDS ìºì‹œë¥¼ ë¨¼ì € í™•ì¸í•˜ê³ , ìºì‹œ ë¯¸ìŠ¤ ì‹œì—ë§Œ í˜¸ì¶œí•´ì•¼ í•¨.
        
        ğŸ”§ v2.0.0 ë³€ê²½ì‚¬í•­:
          - frontend_id â†’ equipment_id ë³€í™˜ (JSON ë§¤í•‘ ì‚¬ìš©)
          - equipment_id ê¸°ë°˜ SQL ì¿¼ë¦¬ ì‹¤í–‰
          - ê²°ê³¼ì— ë§¤í•‘ ì •ë³´ ë³‘í•©
        
        Args:
            frontend_id: Frontend ID (ì˜ˆ: EQ-17-03)
            db_site: MultiConnectionManager Site í‚¤
            db_name: DB ì´ë¦„
            
        Returns:
            EquipmentData or None: ì„¤ë¹„ ë°ì´í„° (ì—†ìœ¼ë©´ None)
        """
        logger.info(f"ğŸ“¡ Fetching equipment: {frontend_id}")
        
        # ===================================================================
        # ğŸ”§ v2.1.1: ì—°ê²°ëœ ì‚¬ì´íŠ¸ í™•ì¸
        # ===================================================================
        mapping_site_id = self._derive_site_id_from_connection(db_site, db_name)
        
        if mapping_site_id is None:
            logger.warning("âš ï¸ No site connected yet, cannot fetch equipment")
            return None
        
        # ===================================================================
        # ğŸ†• v2.0.0: frontend_id â†’ equipment_id ë³€í™˜
        # ===================================================================
        self._load_mapping_config(mapping_site_id)
        
        equipment_id = self._get_equipment_id(frontend_id)
        
        if equipment_id is None:
            logger.warning(f"âš ï¸ No mapping found for frontend_id: {frontend_id}")
            return None
        
        with self._get_session(db_site, db_name) as session:
            try:
                # ğŸ”§ v2.0.0: equipment_id ê¸°ë°˜ ì¡°íšŒ
                result = session.execute(
                    text(SINGLE_EQUIPMENT_QUERY),
                    {"equipment_id": equipment_id}
                )
                row = result.fetchone()
                
                if not row:
                    logger.warning(f"âš ï¸ Equipment not found: {frontend_id} (equipment_id={equipment_id})")
                    return None
                
                columns = result.keys()
                row_dict = dict(zip(columns, row))
                
                # ìƒì‚°ëŸ‰, Tact Timeì€ ë‹¨ì¼ ì¡°íšŒ ì‹œ ë¯¸í¬í•¨ (ìºì‹œ ì‚¬ìš© ê¶Œì¥)
                equipment = self._row_to_equipment_data(row_dict, {}, {})
                
                logger.info(f"âœ… Equipment fetched: {frontend_id} -> {equipment.status}")
                return equipment
                
            except Exception as e:
                logger.error(f"âŒ Failed to fetch equipment {frontend_id}: {e}")
                raise
    
    # ========================================================================
    # ğŸ†• v2.0.0: Equipment IDë¡œ ì„¤ë¹„ ì¡°íšŒ (ì‹ ê·œ)
    # ========================================================================
    
    def fetch_equipment_by_id(
        self,
        equipment_id: int,
        db_site: str = None,
        db_name: str = None
    ) -> Optional[EquipmentData]:
        """
        Equipment IDë¡œ ë‹¨ì¼ ì„¤ë¹„ ì¡°íšŒ
        
        ğŸ†• v2.0.0 ì‹ ê·œ: equipment_id ê¸°ë°˜ ì§ì ‘ ì¡°íšŒ
        
        Args:
            equipment_id: DB Equipment ID
            db_site: MultiConnectionManager Site í‚¤
            db_name: DB ì´ë¦„
            
        Returns:
            EquipmentData or None
        """
        logger.info(f"ğŸ“¡ Fetching equipment by ID: {equipment_id}")
        
        # ğŸ”§ v2.1.1: ì—°ê²°ëœ ì‚¬ì´íŠ¸ í™•ì¸
        mapping_site_id = self._derive_site_id_from_connection(db_site, db_name)
        
        if mapping_site_id is None:
            logger.warning("âš ï¸ No site connected yet, cannot fetch equipment")
            return None
        
        self._load_mapping_config(mapping_site_id)
        
        with self._get_session(db_site, db_name) as session:
            try:
                result = session.execute(
                    text(SINGLE_EQUIPMENT_QUERY),
                    {"equipment_id": equipment_id}
                )
                row = result.fetchone()
                
                if not row:
                    logger.warning(f"âš ï¸ Equipment not found: equipment_id={equipment_id}")
                    return None
                
                columns = result.keys()
                row_dict = dict(zip(columns, row))
                
                equipment = self._row_to_equipment_data(row_dict, {}, {})
                
                logger.info(f"âœ… Equipment fetched: {equipment.frontend_id} -> {equipment.status}")
                return equipment
                
            except Exception as e:
                logger.error(f"âŒ Failed to fetch equipment {equipment_id}: {e}")
                raise
    
    # ========================================================================
    # ğŸ†• v2.1.0: Diff ê³„ì‚° - ìƒì‚°ëŸ‰/Tact Time ì‹¤ì‹œê°„ ë¹„êµ ì¶”ê°€
    # ========================================================================
    
    def compute_diff(
        self,
        site_id: int = 1,
        line_id: int = 1,
        db_site: str = None,
        db_name: str = None
    ) -> List[DeltaUpdate]:
        """
        ì´ì „ ìƒíƒœì™€ í˜„ì¬ ìƒíƒœ ë¹„êµí•˜ì—¬ Delta ìƒì„±
        
        Status Watcherê°€ 10ì´ˆë§ˆë‹¤ í˜¸ì¶œ.
        ë³€ê²½ëœ ì„¤ë¹„ë§Œ Deltaë¡œ ì¶”ì¶œí•˜ì—¬ WebSocket ì „ì†¡.
        
        ğŸ†• v2.1.0 ë³€ê²½ì‚¬í•­:
          - PRODUCTION_SNAPSHOT_QUERY ì‹¤í–‰í•˜ì—¬ ìƒì‚°ëŸ‰ ì¡°íšŒ
          - BATCH_TACT_TIME_QUERY ì‹¤í–‰í•˜ì—¬ Tact Time ì¡°íšŒ
          - EquipmentSnapshotì— production_count, tact_time_seconds í¬í•¨
          - Deltaì— ìƒì‚°ëŸ‰/Tact Time ë³€ê²½ì‚¬í•­ í¬í•¨
        
        ğŸ”§ v2.0.0 ë³€ê²½ì‚¬í•­:
          - STATUS_SNAPSHOT_QUERYê°€ EquipmentId ë°˜í™˜
          - equipment_id â†’ frontend_id ë³€í™˜ (JSON ë§¤í•‘)
          - Deltaì— frontend_id í¬í•¨
        
        [v2.1.0 ì¿¼ë¦¬ ì‹¤í–‰ ìˆœì„œ]
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 1. STATUS_SNAPSHOT_QUERY                                     â”‚
        â”‚    â†’ EquipmentId, Status, StatusChangedAt,                   â”‚
        â”‚      CpuUsagePercent, MemoryUsedMb, MemoryTotalMb            â”‚
        â”‚                                                              â”‚
        â”‚ 2. PRODUCTION_SNAPSHOT_QUERY (ğŸ†• v2.1.0)                     â”‚
        â”‚    â†’ EquipmentId, ProductionCount (ì˜¤ëŠ˜ 00:00 ì´í›„)          â”‚
        â”‚                                                              â”‚
        â”‚ 3. BATCH_TACT_TIME_QUERY (ğŸ†• v2.1.0)                         â”‚
        â”‚    â†’ EquipmentId, TactTimeSeconds (ìµœê·¼ ì‚¬ì´í´)              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        Args:
            site_id: Factory Site ID
            line_id: Factory Line ID
            db_site: DB Site í‚¤
            db_name: DB ì´ë¦„
            
        Returns:
            List[DeltaUpdate]: ë³€ê²½ëœ ì„¤ë¹„ Delta ëª©ë¡ (ë³€ê²½ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
        """
        # ===================================================================
        # ğŸ”§ v2.1.1: ì—°ê²°ëœ ì‚¬ì´íŠ¸ í™•ì¸ (ì‚¬ì´íŠ¸ ì—°ê²° ì „ì´ë©´ ìŠ¤í‚µ)
        # ===================================================================
        mapping_site_id = self._derive_site_id_from_connection(db_site, db_name)
        
        if mapping_site_id is None:
            # ì•„ì§ ì‚¬ì´íŠ¸ê°€ ì—°ê²°ë˜ì§€ ì•ŠìŒ - ì¡°ìš©íˆ ìŠ¤í‚µ
            logger.debug("â³ No site connected yet, skipping diff...")
            return []
        
        # ===================================================================
        # ğŸ”§ v2.1.1: ìë™ ì´ˆê¸°í™” - _previous_stateê°€ ë¹„ì–´ìˆìœ¼ë©´ ìë™ ë¡œë“œ
        # ===================================================================
        if not self._previous_state:
            logger.info(f"ğŸ”„ Auto-initializing previous state for {mapping_site_id}...")
            try:
                self.fetch_all_equipments(site_id, line_id, db_site, db_name)
                logger.info("âœ… Previous state initialized, will compute diff on next cycle")
            except Exception as e:
                logger.error(f"âŒ Failed to auto-initialize previous state: {e}")
            # ì²« ë²ˆì§¸ í˜¸ì¶œì€ ì´ˆê¸°í™”ë§Œ ìˆ˜í–‰, ë‹¤ìŒ í˜¸ì¶œë¶€í„° ì‹¤ì œ diff ê³„ì‚°
            return []
        
        # ===================================================================
        # ğŸ†• v2.0.0: ë§¤í•‘ ë¡œë“œ í™•ì¸
        # ===================================================================
        self._load_mapping_config(mapping_site_id)
        
        # ===================================================================
        # ğŸ†• v2.2.0: ë§¤í•‘ì—ì„œ equipment_id ëª©ë¡ ì¶”ì¶œ
        # ===================================================================
        try:
            equipment_ids_str = self._get_equipment_ids_str()
        except ValueError as e:
            logger.warning(f"âš ï¸ No equipment IDs available: {e}")
            return []
        
        with self._get_session(db_site, db_name) as session:
            try:
                # =============================================================
                # Step 1: ìƒíƒœ ìŠ¤ëƒ…ìƒ· ì¡°íšŒ (ê²½ëŸ‰ ì¿¼ë¦¬)
                # ğŸ”§ v2.2.0: IN ì ˆë¡œ ë§¤í•‘ëœ ì„¤ë¹„ë§Œ ì¡°íšŒ
                # =============================================================
                status_query = STATUS_SNAPSHOT_QUERY.format(equipment_ids=equipment_ids_str)
                status_result = session.execute(text(status_query))
                status_rows = status_result.fetchall()
                
                # equipment_id â†’ status ì •ë³´ ë§µ
                # Column Index: [0] EquipmentId, [1] Status, [2] StatusChangedAt,
                #               [3] CpuUsagePercent, [4] MemoryUsedMb, [5] MemoryTotalMb
                status_map = {}
                for row in status_rows:
                    equipment_id = row[0]
                    if equipment_id:
                        status_map[equipment_id] = {
                            'status': row[1],
                            'status_changed_at': row[2],
                            'cpu_usage_percent': row[3],
                            'memory_used_mb': row[4],
                            'memory_total_mb': row[5]
                        }
                
                # =============================================================
                # ğŸ†• v2.1.0 Step 2: ìƒì‚°ëŸ‰ ìŠ¤ëƒ…ìƒ· ì¡°íšŒ
                # ğŸ”§ v2.2.0: IN ì ˆë¡œ ë§¤í•‘ëœ ì„¤ë¹„ë§Œ ì¡°íšŒ
                # =============================================================
                prod_query = PRODUCTION_SNAPSHOT_QUERY.format(equipment_ids=equipment_ids_str)
                prod_result = session.execute(text(prod_query))
                prod_rows = prod_result.fetchall()
                
                # equipment_id â†’ production_count ë§µ
                # Column Index: [0] EquipmentId, [1] ProductionCount
                prod_map = {row[0]: row[1] for row in prod_rows}
                
                logger.debug(f"  â†’ ìƒì‚°ëŸ‰ Snapshot: {len(prod_map)}ê±´ ì¡°íšŒ")
                
                # =============================================================
                # ğŸ†• v2.1.0 Step 3: Tact Time ì¡°íšŒ
                # ğŸ”§ v2.2.0: IN ì ˆë¡œ ë§¤í•‘ëœ ì„¤ë¹„ë§Œ ì¡°íšŒ
                # =============================================================
                tact_query = BATCH_TACT_TIME_QUERY.format(equipment_ids=equipment_ids_str)
                tact_result = session.execute(text(tact_query))
                tact_rows = tact_result.fetchall()
                
                # equipment_id â†’ tact_time_seconds ë§µ
                # Column Index: [0] EquipmentId, [1] TactTimeSeconds
                tact_map = {row[0]: row[1] for row in tact_rows}
                
                logger.debug(f"  â†’ Tact Time Snapshot: {len(tact_map)}ê±´ ì¡°íšŒ")
                
                # =============================================================
                # Step 4: Diff ê³„ì‚°
                # =============================================================
                deltas = []
                timestamp = datetime.utcnow()
                
                for equipment_id, status_info in status_map.items():
                    # ğŸ†• v2.0.0: equipment_id â†’ frontend_id ë³€í™˜
                    frontend_id = self._get_frontend_id(equipment_id)
                    if not frontend_id:
                        # ë§¤í•‘ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                        continue
                    
                    # ğŸ†• v2.1.0: ìƒì‚°ëŸ‰, Tact Time ì¡°íšŒ
                    production_count = prod_map.get(equipment_id, 0)
                    tact_time_seconds = tact_map.get(equipment_id)
                    
                    # Memory ì‚¬ìš©ìœ¨ ê³„ì‚°
                    memory_usage_percent = None
                    if status_info['memory_used_mb'] and status_info['memory_total_mb']:
                        memory_usage_percent = calculate_memory_usage_percent(
                            status_info['memory_used_mb'],
                            status_info['memory_total_mb']
                        )
                    
                    # ğŸ†• v2.1.0: í˜„ì¬ ìŠ¤ëƒ…ìƒ· ìƒì„± (ìƒì‚°ëŸ‰, Tact Time í¬í•¨)
                    current = EquipmentSnapshot(
                        frontend_id=frontend_id,
                        status=status_info['status'],
                        status_changed_at=status_info['status_changed_at'],
                        cpu_usage_percent=status_info['cpu_usage_percent'],
                        memory_usage_percent=memory_usage_percent,
                        production_count=production_count,           # ğŸ†• v2.1.0
                        tact_time_seconds=tact_time_seconds          # ğŸ†• v2.1.0
                    )
                    
                    # ì´ì „ ìŠ¤ëƒ…ìƒ· ì¡°íšŒ
                    previous = self._previous_state.get(frontend_id)
                    
                    if previous:
                        # Diff ê³„ì‚° (production_count, tact_time_seconds í¬í•¨ë¨)
                        changes = compute_delta(previous, current)
                        
                        if changes:
                            deltas.append(DeltaUpdate(
                                frontend_id=frontend_id,
                                changes=changes,
                                timestamp=timestamp
                            ))
                    
                    # ì´ì „ ìƒíƒœ ì—…ë°ì´íŠ¸
                    self._previous_state[frontend_id] = current
                
                if deltas:
                    logger.info(f"ğŸ”„ Detected {len(deltas)} changes (including production/tact_time)")
                
                return deltas
                
            except Exception as e:
                logger.error(f"âŒ Failed to compute diff: {e}", exc_info=True)
                return []
    
    # ========================================================================
    # í†µê³„ ê³„ì‚°
    # ========================================================================
    
    def calculate_stats(self, equipments: List[EquipmentData]) -> StatusStats:
        """
        ì„¤ë¹„ ëª©ë¡ì—ì„œ ìƒíƒœë³„ í†µê³„ ê³„ì‚°
        
        Args:
            equipments: EquipmentData ëª©ë¡
            
        Returns:
            StatusStats: ìƒíƒœë³„ ì¹´ìš´íŠ¸
        """
        return compute_status_stats(equipments)
    
    # ========================================================================
    # ìºì‹œ ê´€ë¦¬
    # ========================================================================
    
    def clear_cache(self):
        """In-Memory ìºì‹œ ì´ˆê¸°í™” (í…ŒìŠ¤íŠ¸/ë¦¬ì…‹ìš©)"""
        self._previous_state.clear()
        self._last_fetch_time = None
        logger.info("ğŸ—‘ï¸ UDS state cache cleared")
    
    def clear_mapping_cache(self):
        """
        ğŸ†• v2.0.0: ë§¤í•‘ ìºì‹œ ì´ˆê¸°í™”
        Site ë³€ê²½ ì‹œ ë˜ëŠ” ë§¤í•‘ ê°±ì‹  ì‹œ í˜¸ì¶œ
        """
        self._mapping_cache.clear()
        self._reverse_mapping.clear()
        self._current_site_id = None
        self._mapping_loaded_at = None
        logger.info("ğŸ—‘ï¸ UDS mapping cache cleared")
    
    def clear_all_caches(self):
        """
        ğŸ†• v2.0.0: ëª¨ë“  ìºì‹œ ì´ˆê¸°í™”
        """
        self.clear_cache()
        self.clear_mapping_cache()
        logger.info("ğŸ—‘ï¸ All UDS caches cleared")
    
    def reload_mapping(self, site_id: str = None):
        """
        ğŸ†• v2.0.0: ë§¤í•‘ ê°•ì œ ì¬ë¡œë“œ
        
        Args:
            site_id: Site ID (Noneì´ë©´ í˜„ì¬ Site)
        """
        target_site = site_id or self._current_site_id
        if target_site:
            self._load_mapping_config(target_site, force_reload=True)
    
    def get_cache_info(self) -> Dict[str, Any]:
        """ìºì‹œ ìƒíƒœ ì •ë³´"""
        return {
            "cached_count": len(self._previous_state),
            "last_fetch_time": self._last_fetch_time.isoformat() if self._last_fetch_time else None,
            "frontend_ids_sample": list(self._previous_state.keys())[:10],
            # ğŸ†• v2.0.0: ë§¤í•‘ ìºì‹œ ì •ë³´
            "mapping_cache_count": len(self._mapping_cache),
            "current_site_id": self._current_site_id,
            "mapping_loaded_at": self._mapping_loaded_at.isoformat() if self._mapping_loaded_at else None
        }
    
    def get_mapping_info(self) -> Dict[str, Any]:
        """
        ğŸ†• v2.0.0: ë§¤í•‘ ìƒíƒœ ì •ë³´
        """
        return {
            "site_id": self._current_site_id,
            "total_mappings": len(self._mapping_cache),
            "loaded_at": self._mapping_loaded_at.isoformat() if self._mapping_loaded_at else None,
            "equipment_ids_sample": list(self._mapping_cache.keys())[:10],
            "frontend_ids_sample": list(self._reverse_mapping.keys())[:10]
        }
    
    # ========================================================================
    # Private í—¬í¼ ë©”ì„œë“œ
    # ========================================================================
    
    def _row_to_equipment_data(
        self,
        row: Dict[str, Any],
        prod_map: Dict[int, int],  # ğŸ”§ v2.0.0: equipment_id ê¸°ë°˜
        tact_map: Dict[int, float],  # ğŸ”§ v2.0.0: equipment_id ê¸°ë°˜
        alarm_repeat_map: Dict[int, int] = None,    # âœ… ì¶”ê°€!
        state_history_map: Dict[int, List[Dict[str, Any]]] = None    # ğŸ†• v2.4.0 ì¶”ê°€!
    ) -> EquipmentData:
        """
        DB Row â†’ EquipmentData ë³€í™˜
        
        ğŸ”§ v2.0.0 ë³€ê²½ì‚¬í•­:
          - SQL ê²°ê³¼ì— FrontendId, GridRow, GridCol ì—†ìŒ
          - JSON ë§¤í•‘ì—ì„œ ê°€ì ¸ì™€ì„œ ë³‘í•©
          - ë§¤í•‘ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
        
        BATCH_EQUIPMENT_QUERY ì»¬ëŸ¼ ì¸ë±ìŠ¤ (v2.0.0):
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         0: EquipmentId      (core.Equipment)
         1: EquipmentName    (core.Equipment)
         2: LineName         (core.Equipment)
         3: Status           (log.EquipmentState)
         4: StatusChangedAt  (log.EquipmentState)
         5: ProductModel     (log.Lotinfo)
         6: LotId            (log.Lotinfo)
         7: TargetCount      (log.Lotinfo.LotQty)   # âœ… ì¶”ê°€!
         7: LotStartTime     (log.Lotinfo)
         8: CpuUsagePercent  (log.EquipmentPCInfo)
         9: MemoryTotalMb    (log.EquipmentPCInfo)
        10: MemoryUsedMb     (log.EquipmentPCInfo)
        11: DisksTotalGb     (log.EquipmentPCInfo)
        12: DisksUsedGb      (log.EquipmentPCInfo)
        
        âŒ ì œê±°ë¨ (v2.0.0):
        13: GridRow          â†’ JSON ë§¤í•‘ì—ì„œ ê°€ì ¸ì˜´
        14: GridCol          â†’ JSON ë§¤í•‘ì—ì„œ ê°€ì ¸ì˜´
        15: FrontendId       â†’ JSON ë§¤í•‘ì—ì„œ ê°€ì ¸ì˜´
        """
        equipment_id = row['EquipmentId']
        
        # ===================================================================
        # ğŸ†• v2.0.0: JSON ë§¤í•‘ì—ì„œ FrontendId, GridRow, GridCol ê°€ì ¸ì˜¤ê¸°
        # ===================================================================
        mapping_info = self._get_mapping_info(equipment_id)
        
        if mapping_info:
            frontend_id = mapping_info.get('frontend_id')
            grid_row = mapping_info.get('grid_row', 0)
            grid_col = mapping_info.get('grid_col', 0)
        else:
            # ë§¤í•‘ ì—†ëŠ” ê²½ìš°: ê¸°ë³¸ê°’ ë˜ëŠ” equipment_id ê¸°ë°˜ ìƒì„±
            frontend_id = None
            grid_row = 0
            grid_col = 0
            logger.debug(f"âš ï¸ No mapping for equipment_id={equipment_id}")
        
        # FrontendId ì—†ìœ¼ë©´ equipment_id ê¸°ë°˜ ì„ì‹œ ID ìƒì„±
        if not frontend_id:
            # ì„ì‹œ ID: EQ-00-{equipment_id} í˜•ì‹
            frontend_id = f"EQ-00-{equipment_id:02d}"
        
        # Status Enum ë³€í™˜
        status_str = row.get('Status') or 'DISCONNECTED'
        try:
            status = EquipmentStatus(status_str)
        except ValueError:
            status = EquipmentStatus.DISCONNECTED
        
        # Memory/Disk ì‚¬ìš©ìœ¨ ê³„ì‚°
        memory_usage = None
        if row.get('MemoryTotalMb') and row.get('MemoryUsedMb'):
            memory_usage = calculate_memory_usage_percent(
                row['MemoryUsedMb'],
                row['MemoryTotalMb']
            )
        
        disk_usage = None
        if row.get('DisksTotalGb') and row.get('DisksUsedGb'):
            disk_usage = calculate_disk_usage_percent(
                row['DisksUsedGb'],
                row['DisksTotalGb']
            )
        
        # ğŸ”§ v2.0.0: ìƒì‚°ëŸ‰/Tact Timeì€ equipment_idë¡œ ì¡°íšŒ
        production_count = prod_map.get(equipment_id, 0)
        tact_time = tact_map.get(equipment_id)

        # ğŸ†• v2.3.0: ì•ŒëŒ ë°˜ë³µ íšŸìˆ˜
        alarm_repeat_count = 0
        if alarm_repeat_map:
            alarm_repeat_count = alarm_repeat_map.get(equipment_id, 0)

        # ğŸ†• v2.4.0: ìƒíƒœ íˆìŠ¤í† ë¦¬ (MiniTimelineìš©)
        state_history = []
        if state_history_map:
            state_history = state_history_map.get(equipment_id, [])
        
        return EquipmentData(
            equipment_id=equipment_id,
            frontend_id=frontend_id,
            equipment_name=row.get('EquipmentName', ''),
            line_name=row.get('LineName', ''),
            status=status,
            status_changed_at=row.get('StatusChangedAt'),
            alarm_code=row.get('AlarmCode'),
            alarm_message=row.get('AlarmMessage'),
            alarm_repeat_count=alarm_repeat_count,    # âœ… ì¶”ê°€!
            product_model=row.get('ProductModel'),
            lot_id=row.get('LotId'),
            lot_start_time=row.get('LotStartTime'),
            target_count=row.get('TargetCount', 0),   # âœ… ì¶”ê°€!
            production_count=production_count,
            tact_time_seconds=tact_time,
            cpu_usage_percent=row.get('CpuUsagePercent'),
            memory_usage_percent=memory_usage,
            disk_usage_percent=disk_usage,
            grid_row=grid_row,
            grid_col=grid_col,
            state_history=state_history    # ğŸ†• v2.4.0 ì¶”ê°€!
        )
    
    def _update_previous_state(self, equipment: EquipmentData):
        """
        Diff ë¹„êµìš© ì´ì „ ìƒíƒœ ì—…ë°ì´íŠ¸
        
        ğŸ†• v2.1.0: production_count, tact_time_seconds í¬í•¨
        """
        self._previous_state[equipment.frontend_id] = EquipmentSnapshot(
            frontend_id=equipment.frontend_id,
            status=equipment.status.value if hasattr(equipment.status, 'value') else equipment.status,
            status_changed_at=equipment.status_changed_at,
            cpu_usage_percent=equipment.cpu_usage_percent,
            memory_usage_percent=equipment.memory_usage_percent,
            production_count=equipment.production_count,          # ğŸ†• v2.1.0
            tact_time_seconds=equipment.tact_time_seconds         # ğŸ†• v2.1.0
        )

    # =============================================================================
    # ğŸ†• Remote Alarm Codes ë¡œë“œ (v2.5.0)
    # =============================================================================

    def load_remote_alarm_codes(self) -> set:
        """
        ref.RemoteAlarmList í…Œì´ë¸”ì—ì„œ Remote Alarm Code ëª©ë¡ ë¡œë“œ
        
        Returns:
            set: Remote Alarm Code Set (ì˜ˆ: {61, 62, 86, 10047, ...})
        """
        if self._remote_alarm_codes_loaded:
            return self._remote_alarm_codes
        
        logger.info("ğŸ“¡ Loading Remote Alarm Codes from DB...")
        
        try:
            from .uds_queries import REMOTE_ALARM_CODES_QUERY
            
            conn = self._get_connection()
            if not conn:
                logger.error("âŒ No database connection")
                return set()
            
            cursor = conn.cursor()
            cursor.execute(REMOTE_ALARM_CODES_QUERY)
            rows = cursor.fetchall()
            
            self._remote_alarm_codes = {row[0] for row in rows}
            self._remote_alarm_codes_loaded = True
            
            logger.info(f"âœ… Loaded {len(self._remote_alarm_codes)} Remote Alarm Codes: {self._remote_alarm_codes}")
            
            return self._remote_alarm_codes
            
        except Exception as e:
            logger.error(f"âŒ Failed to load Remote Alarm Codes: {e}")
            # Fallback: ê¸°ë³¸ê°’ ë°˜í™˜
            return {61, 62, 86, 10047, 10048, 10051, 10052, 10055, 10056, 10057, 10058, 10077}

    def get_remote_alarm_codes(self) -> list:
        """
        Remote Alarm Code ëª©ë¡ ë°˜í™˜ (APIìš©)
        
        Returns:
            list: Remote Alarm Code ëª©ë¡
        """
        codes = self.load_remote_alarm_codes()
        return sorted(list(codes))

    def is_remote_alarm(self, alarm_code: int) -> bool:
        """
        íŠ¹ì • ì•ŒëŒ ì½”ë“œê°€ Remote Alarmì¸ì§€ í™•ì¸
        
        Args:
            alarm_code: ì•ŒëŒ ì½”ë“œ
            
        Returns:
            bool: Remote Alarm ì—¬ë¶€
        """
        if not alarm_code:
            return False
        codes = self.load_remote_alarm_codes()
        return alarm_code in codes


# =============================================================================
# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
# =============================================================================
# ì•± ì „ì—­ì—ì„œ ë™ì¼ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© (In-Memory ìºì‹œ ê³µìœ )
uds_service = UDSService()