"""
analytics/trends.py
íŠ¸ë Œë“œ ë¶„ì„ (ì‹œê³„ì—´) ë¼ìš°í„°

@version 1.0.0
@changelog
- v1.0.0: analytics.pyì—ì„œ ë¶„ë¦¬
  - ì‹¤ì œ DB ìŠ¤í‚¤ë§ˆ ì‚¬ìš©
  - MSSQL ë‚ ì§œ ì§‘ê³„ í•¨ìˆ˜ ì‚¬ìš© (TimescaleDB â†’ MSSQL ì „í™˜)
  - production: log.CycleTime ê¸°ë°˜
  - alarm: log.AlarmEvent ê¸°ë°˜
  - âš ï¸ í˜¸í™˜ì„±: ê¸°ì¡´ API ì—”ë“œí¬ì¸íŠ¸ /trends ìœ ì§€

@description
íŠ¸ë Œë“œ ë¶„ì„ ë©”íŠ¸ë¦­:
- production: ìƒì‚°ëŸ‰ íŠ¸ë Œë“œ (Cycle ì™„ë£Œ ìˆ˜)
- alarm: ì•ŒëŒ ë°œìƒ íŠ¸ë Œë“œ
- defect: ë¶ˆëŸ‰ë¥  íŠ¸ë Œë“œ (ë°ì´í„° ì—†ìŒ)
- oee: OEE íŠ¸ë Œë“œ (ê³„ì‚° ê¸°ë°˜)

@dependencies
- helpers: safe_percentage, get_default_date_range
- queries: ê° ë¶„ì„ ìœ í˜•ë³„ ì¿¼ë¦¬

ì‘ì„±ì¼: 2026-02-02
ìˆ˜ì •ì¼: 2026-02-02
"""

from fastapi import APIRouter, Query
from typing import Optional, List, Dict
import logging

from .helpers import (
    safe_percentage,
    get_default_date_range,
    validate_calculation_period,
    validate_metric_type,
    validate_interval
)
from ...database.connection import get_db_connection, return_db_connection
from ...utils.errors import (
    handle_errors,
    handle_db_error,
    ValidationError,
    NotFoundError
)

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

router = APIRouter()


# ============================================================================
# ì‹œê°„ ê°„ê²© ë§¤í•‘ (MSSQLìš©)
# ============================================================================

INTERVAL_SQL_MAP = {
    "1hour": {
        "datepart": "hour",
        "group_format": "DATEADD(HOUR, DATEDIFF(HOUR, 0, {column}), 0)"
    },
    "1day": {
        "datepart": "day",
        "group_format": "CAST({column} AS DATE)"
    },
    "1week": {
        "datepart": "week",
        "group_format": "DATEADD(WEEK, DATEDIFF(WEEK, 0, {column}), 0)"
    }
}


# ============================================================================
# íŠ¸ë Œë“œ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸
# ============================================================================

@router.get(
    "/trends",
    summary="íŠ¸ë Œë“œ ë¶„ì„",
    description="ì‹œê³„ì—´ ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„"
)
@handle_errors
async def get_trends(
    metric: str = Query(
        default="production",
        description="íŠ¸ë Œë“œ ë©”íŠ¸ë¦­: production, alarm, defect, oee"
    ),
    equipment_id: Optional[int] = Query(
        None,
        description="ì„¤ë¹„ ID (ì—†ìœ¼ë©´ ì „ì²´)"
    ),
    frontend_id: Optional[str] = Query(
        None,
        description="Frontend ID"
    ),
    interval: str = Query(
        default="1day",
        description="ì‹œê°„ ê°„ê²©: 1hour, 1day, 1week"
    ),
    limit: int = Query(
        default=30,
        ge=1,
        le=365,
        description="ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜"
    )
):
    """
    íŠ¸ë Œë“œ ë¶„ì„ (ì‹œê³„ì—´)
    
    ğŸ†• v1.0.0: MSSQL ë‚ ì§œ ì§‘ê³„ í•¨ìˆ˜ ì‚¬ìš©
    
    **ë©”íŠ¸ë¦­ ìœ í˜•:**
    - production: Cycle ì™„ë£Œ ìˆ˜ íŠ¸ë Œë“œ
    - alarm: ì•ŒëŒ ë°œìƒ íŠ¸ë Œë“œ
    - defect: ë¶ˆëŸ‰ë¥  íŠ¸ë Œë“œ (ë°ì´í„° ì—†ìŒ)
    - oee: OEE íŠ¸ë Œë“œ (ê³„ì‚° ê¸°ë°˜)
    
    **ì‹œê°„ ê°„ê²©:**
    - 1hour: ì‹œê°„ë³„ ì§‘ê³„
    - 1day: ì¼ë³„ ì§‘ê³„
    - 1week: ì£¼ë³„ ì§‘ê³„
    """
    logger.info(
        f"ğŸš€ íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘: metric={metric}, equipment={equipment_id}, "
        f"interval={interval}, limit={limit}"
    )
    
    # ê²€ì¦
    validate_metric_type(metric)
    validate_interval(interval)
    
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        trends = []
        
        if metric == "production":
            trends = await _get_production_trends(
                cursor, equipment_id, interval, limit
            )
        elif metric == "alarm":
            trends = await _get_alarm_trends(
                cursor, equipment_id, interval, limit
            )
        elif metric == "defect":
            trends = await _get_defect_trends(
                cursor, equipment_id, interval, limit
            )
        elif metric == "oee":
            trends = await _get_oee_trends(
                cursor, equipment_id, interval, limit
            )
        
        cursor.close()
        
        if not trends:
            logger.warning(f"âš ï¸ íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ: metric={metric}")
            return {
                "metric": metric,
                "equipment_id": equipment_id,
                "interval": interval,
                "trends": [],
                "count": 0,
                "message": "í•´ë‹¹ ì¡°ê±´ì˜ íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
            }
        
        logger.info(f"âœ… íŠ¸ë Œë“œ ë¶„ì„ ì™„ë£Œ: {len(trends)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
        
        return {
            "metric": metric,
            "equipment_id": equipment_id,
            "interval": interval,
            "trends": trends,
            "count": len(trends)
        }
        
    except (ValidationError, NotFoundError):
        raise
    except Exception as e:
        handle_db_error(e, "íŠ¸ë Œë“œ ë¶„ì„")
    finally:
        if conn:
            return_db_connection(conn)


# ============================================================================
# íŠ¸ë Œë“œ ìœ í˜•ë³„ í•¨ìˆ˜
# ============================================================================

async def _get_production_trends(
    cursor,
    equipment_id: Optional[int],
    interval: str,
    limit: int
) -> List[Dict]:
    """
    ìƒì‚°ëŸ‰ íŠ¸ë Œë“œ (Cycle ì™„ë£Œ ìˆ˜)
    """
    logger.debug(f"ğŸ“Š ìƒì‚°ëŸ‰ íŠ¸ë Œë“œ (interval={interval})")
    
    interval_info = INTERVAL_SQL_MAP[interval]
    time_bucket = interval_info["group_format"].format(column="ct.[Time]")
    
    if equipment_id:
        query = f"""
            SELECT TOP (?)
                {time_bucket} as bucket,
                COUNT(*) as cycle_count
            FROM [log].[CycleTime] ct
            WHERE ct.EquipmentId = ?
            GROUP BY {time_bucket}
            ORDER BY bucket DESC
        """
        cursor.execute(query, (limit, equipment_id))
    else:
        query = f"""
            SELECT TOP (?)
                {time_bucket} as bucket,
                COUNT(*) as cycle_count
            FROM [log].[CycleTime] ct
            GROUP BY {time_bucket}
            ORDER BY bucket DESC
        """
        cursor.execute(query, (limit,))
    
    trends = []
    for row in cursor.fetchall():
        trends.append({
            "timestamp": row[0].isoformat() if row[0] else None,
            "cycle_count": row[1]
        })
    
    # ì‹œê°„ìˆœ ì •ë ¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„°)
    trends.reverse()
    
    return trends


async def _get_alarm_trends(
    cursor,
    equipment_id: Optional[int],
    interval: str,
    limit: int
) -> List[Dict]:
    """
    ì•ŒëŒ ë°œìƒ íŠ¸ë Œë“œ
    """
    logger.debug(f"ğŸ“Š ì•ŒëŒ íŠ¸ë Œë“œ (interval={interval})")
    
    interval_info = INTERVAL_SQL_MAP[interval]
    time_bucket = interval_info["group_format"].format(column="ae.OccurredAtUtc")
    
    if equipment_id:
        query = f"""
            SELECT TOP (?)
                {time_bucket} as bucket,
                COUNT(CASE WHEN ae.IsSet = 1 THEN 1 END) as alarm_count,
                COUNT(DISTINCT ae.AlarmCode) as unique_alarm_codes
            FROM [log].[AlarmEvent] ae
            WHERE ae.EquipmentId = ?
            GROUP BY {time_bucket}
            ORDER BY bucket DESC
        """
        cursor.execute(query, (limit, equipment_id))
    else:
        query = f"""
            SELECT TOP (?)
                {time_bucket} as bucket,
                COUNT(CASE WHEN ae.IsSet = 1 THEN 1 END) as alarm_count,
                COUNT(DISTINCT ae.AlarmCode) as unique_alarm_codes
            FROM [log].[AlarmEvent] ae
            GROUP BY {time_bucket}
            ORDER BY bucket DESC
        """
        cursor.execute(query, (limit,))
    
    trends = []
    for row in cursor.fetchall():
        trends.append({
            "timestamp": row[0].isoformat() if row[0] else None,
            "alarm_count": row[1],
            "unique_alarm_codes": row[2]
        })
    
    trends.reverse()
    return trends


async def _get_defect_trends(
    cursor,
    equipment_id: Optional[int],
    interval: str,
    limit: int
) -> List[Dict]:
    """
    ë¶ˆëŸ‰ë¥  íŠ¸ë Œë“œ
    
    âš ï¸ í˜„ì¬ ë¶ˆëŸ‰ ë°ì´í„° ì—†ìŒ - placeholder
    """
    logger.debug(f"ğŸ“Š ë¶ˆëŸ‰ë¥  íŠ¸ë Œë“œ (interval={interval})")
    logger.warning("âš ï¸ ë¶ˆëŸ‰ ë°ì´í„° í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ê²°ê³¼ ë°˜í™˜")
    
    # TODO: ë¶ˆëŸ‰ ë°ì´í„° í…Œì´ë¸”ì´ ì¶”ê°€ë˜ë©´ êµ¬í˜„
    return []


async def _get_oee_trends(
    cursor,
    equipment_id: Optional[int],
    interval: str,
    limit: int
) -> List[Dict]:
    """
    OEE íŠ¸ë Œë“œ (ê³„ì‚° ê¸°ë°˜)
    
    ì¼ë³„ë¡œ OEEë¥¼ ê³„ì‚°í•˜ì—¬ íŠ¸ë Œë“œ ìƒì„±
    """
    logger.debug(f"ğŸ“Š OEE íŠ¸ë Œë“œ (interval={interval})")
    
    interval_info = INTERVAL_SQL_MAP[interval]
    time_bucket_status = interval_info["group_format"].format(column="es.OccurredAtUtc")
    time_bucket_cycle = interval_info["group_format"].format(column="ct.[Time]")
    
    # ì´ ì¿¼ë¦¬ëŠ” ë³µì¡í•˜ë¯€ë¡œ ì¼ë³„ ì§‘ê³„ë§Œ ì§€ì›
    if interval != "1day":
        logger.warning("âš ï¸ OEE íŠ¸ë Œë“œëŠ” í˜„ì¬ ì¼ë³„(1day) ì§‘ê³„ë§Œ ì§€ì›í•©ë‹ˆë‹¤")
    
    # ìƒíƒœ ë°ì´í„° ê¸°ë°˜ Availability ì§‘ê³„
    if equipment_id:
        status_query = f"""
            SELECT TOP (?)
                CAST(es.OccurredAtUtc AS DATE) as bucket,
                COUNT(*) as total_records,
                COUNT(CASE WHEN es.Status = 'RUNNING' THEN 1 END) as running_records
            FROM [log].[EquipmentState] es
            WHERE es.EquipmentId = ?
            GROUP BY CAST(es.OccurredAtUtc AS DATE)
            ORDER BY bucket DESC
        """
        cursor.execute(status_query, (limit, equipment_id))
    else:
        status_query = f"""
            SELECT TOP (?)
                CAST(es.OccurredAtUtc AS DATE) as bucket,
                COUNT(*) as total_records,
                COUNT(CASE WHEN es.Status = 'RUNNING' THEN 1 END) as running_records
            FROM [log].[EquipmentState] es
            GROUP BY CAST(es.OccurredAtUtc AS DATE)
            ORDER BY bucket DESC
        """
        cursor.execute(status_query, (limit,))
    
    status_data = {}
    for row in cursor.fetchall():
        bucket = row[0]
        total = row[1] or 1
        running = row[2] or 0
        status_data[bucket] = {
            "availability": running / total if total > 0 else 0
        }
    
    # Cycle ë°ì´í„° ê¸°ë°˜ ìƒì‚°ëŸ‰ ì§‘ê³„
    if equipment_id:
        cycle_query = f"""
            SELECT 
                CAST(ct.[Time] AS DATE) as bucket,
                COUNT(*) as cycle_count
            FROM [log].[CycleTime] ct
            WHERE ct.EquipmentId = ?
              AND CAST(ct.[Time] AS DATE) IN (SELECT CAST(es.OccurredAtUtc AS DATE) 
                                               FROM [log].[EquipmentState] es 
                                               WHERE es.EquipmentId = ?)
            GROUP BY CAST(ct.[Time] AS DATE)
        """
        cursor.execute(cycle_query, (equipment_id, equipment_id))
    else:
        cycle_query = f"""
            SELECT 
                CAST(ct.[Time] AS DATE) as bucket,
                COUNT(*) as cycle_count
            FROM [log].[CycleTime] ct
            GROUP BY CAST(ct.[Time] AS DATE)
        """
        cursor.execute(cycle_query)
    
    cycle_data = {}
    for row in cursor.fetchall():
        cycle_data[row[0]] = row[1]
    
    # OEE ê³„ì‚° ë° íŠ¸ë Œë“œ ìƒì„±
    trends = []
    for bucket, status_info in sorted(status_data.items()):
        availability = status_info["availability"]
        cycle_count = cycle_data.get(bucket, 0)
        
        # ê°„ë‹¨í•œ Performance ê³„ì‚° (ê¸°ì¤€ê°’ í•„ìš”)
        # ì—¬ê¸°ì„œëŠ” í•˜ë£¨ 8ì‹œê°„ ê°€ë™, Tact Time 60ì´ˆ ê¸°ì¤€
        theoretical_daily_cycles = 8 * 60  # 480 cycles/day
        performance = min(cycle_count / theoretical_daily_cycles, 1.0) if theoretical_daily_cycles > 0 else 0
        
        quality = 1.0  # í’ˆì§ˆ ë°ì´í„° ì—†ìŒ
        
        oee = availability * performance * quality
        
        trends.append({
            "timestamp": bucket.isoformat() if hasattr(bucket, 'isoformat') else str(bucket),
            "oee_percent": round(oee * 100, 2),
            "availability_percent": round(availability * 100, 2),
            "performance_percent": round(performance * 100, 2),
            "quality_percent": round(quality * 100, 2),
            "cycle_count": cycle_count
        })
    
    return trends
